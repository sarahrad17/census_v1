{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checked!!\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_order = [124, 116, 118, 123, 115, 117, 125, 51, 59, 111, 32, 102, \n",
    "              108, 42, 62, 37, 99, 44, 103, 48, 26, 96, 31, 106, 95, \n",
    "              45, 105, 38, 41, 107, 119, 97, 33, 43, 30, 94, 13, 79, \n",
    "              15, 83, 80, 27, 29, 12, 88, 76, 11, 78, 4, 17, 81, 75, \n",
    "              19, 74, 14, 6, 67, 68, 1, 10, 65, 5, 64, 63, 0, 66, 69, \n",
    "              71, 70, 2, 73, 8, 7, 84, 3, 72, 91, 77, 85, 20, 82, 21,\n",
    "              24, 9, 18, 28, 104, 22, 110, 87, 25, 86, 89, 92, 35, 90,\n",
    "              40, 36, 100, 50, 47, 16, 93, 39, 23, 98, 34, 56, 114, 57, \n",
    "              101, 113, 54, 46, 52, 49, 60, 55, 120, 53, 58, 109, 112, 61, 122, 121]\n",
    "\n",
    "\n",
    "races2 = ['White alone',\n",
    "       'Black or African American alone',\n",
    "       'American Indian and Alaska Native alone',\n",
    "       'Asian alone',\n",
    "       'Native Hawaiian and Other Pacific Islander alone',\n",
    "       'Some Other Race alone',\n",
    "       'White; Black or African American',\n",
    "       'White; American Indian and Alaska Native',\n",
    "       'White; Asian',\n",
    "       'White; Native Hawaiian and Other Pacific Islander',\n",
    "       'White; Some Other Race',\n",
    "       'Black or African American; American Indian and Alaska Native',\n",
    "       'Black or African American; Asian',\n",
    "       'Black or African American; Native Hawaiian and Other Pacific Islander',\n",
    "       'Black or African American; Some Other Race',\n",
    "       'American Indian and Alaska Native; Asian',\n",
    "       'American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
    "       'American Indian and Alaska Native; Some Other Race',\n",
    "       'Asian; Native Hawaiian and Other Pacific Islander',\n",
    "       'Asian; Some Other Race',\n",
    "       'Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'White; Black or African American; American Indian and Alaska Native',\n",
    "       'White; Black or African American; Asian',\n",
    "       'White; Black or African American; Native Hawaiian and Other Pacific Islander',\n",
    "       'White; Black or African American; Some Other Race',\n",
    "       'White; American Indian and Alaska Native; Asian',\n",
    "       'White; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
    "       'White; American Indian and Alaska Native; Some Other Race',\n",
    "       'White; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "       'White; Asian; Some Other Race',\n",
    "       'White; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'Black or African American; American Indian and Alaska Native; Asian',\n",
    "       'Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
    "       'Black or African American; American Indian and Alaska Native; Some Other Race',\n",
    "       'Black or African American; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "       'Black or African American; Asian; Some Other Race',\n",
    "       'Black or African American; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "       'American Indian and Alaska Native; Asian; Some Other Race',\n",
    "       'American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'White; Black or African American; American Indian and Alaska Native; Asian',\n",
    "       'White; Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
    "       'White; Black or African American; American Indian and Alaska Native; Some Other Race',\n",
    "       'White; Black or African American; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "       'White; Black or African American; Asian; Some Other Race',\n",
    "       'White; Black or African American; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'White; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "       'White; American Indian and Alaska Native; Asian; Some Other Race',\n",
    "       'White; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'White; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "       'Black or African American; American Indian and Alaska Native; Asian; Some Other Race',\n",
    "       'Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'Black or African American; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'White; Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "       'White; Black or African American; American Indian and Alaska Native; Asian; Some Other Race',\n",
    "       'White; Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'White; Black or African American; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'White; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'White; Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race']\n",
    "\n",
    "races = ['Total!!Population of one race!!White alone',\n",
    "           'Total!!Population of one race!!Black or African American alone',\n",
    "           'Total!!Population of one race!!American Indian and Alaska Native alone',\n",
    "           'Total!!Population of one race!!Asian alone',\n",
    "           'Total!!Population of one race!!Native Hawaiian and Other Pacific Islander alone',\n",
    "           'Total!!Population of one race!!Some Other Race alone',\n",
    "           'Total!!Two or More Races!!Population of two races!!White; Black or African American',\n",
    "           'Total!!Two or More Races!!Population of two races!!White; American Indian and Alaska Native',\n",
    "           'Total!!Two or More Races!!Population of two races!!White; Asian',\n",
    "           'Total!!Two or More Races!!Population of two races!!White; Native Hawaiian and Other Pacific Islander',\n",
    "           'Total!!Two or More Races!!Population of two races!!White; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of two races!!Black or African American; American Indian and Alaska Native',\n",
    "           'Total!!Two or More Races!!Population of two races!!Black or African American; Asian',\n",
    "           'Total!!Two or More Races!!Population of two races!!Black or African American; Native Hawaiian and Other Pacific Islander',\n",
    "           'Total!!Two or More Races!!Population of two races!!Black or African American; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of two races!!American Indian and Alaska Native; Asian',\n",
    "           'Total!!Two or More Races!!Population of two races!!American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
    "           'Total!!Two or More Races!!Population of two races!!American Indian and Alaska Native; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of two races!!Asian; Native Hawaiian and Other Pacific Islander',\n",
    "           'Total!!Two or More Races!!Population of two races!!Asian; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of two races!!Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of three races!!White; Black or African American; American Indian and Alaska Native',\n",
    "           'Total!!Two or More Races!!Population of three races!!White; Black or African American; Asian',\n",
    "           'Total!!Two or More Races!!Population of three races!!White; Black or African American; Native Hawaiian and Other Pacific Islander',\n",
    "           'Total!!Two or More Races!!Population of three races!!White; Black or African American; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of three races!!White; American Indian and Alaska Native; Asian',\n",
    "           'Total!!Two or More Races!!Population of three races!!White; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
    "           'Total!!Two or More Races!!Population of three races!!White; American Indian and Alaska Native; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of three races!!White; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "           'Total!!Two or More Races!!Population of three races!!White; Asian; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of three races!!White; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of three races!!Black or African American; American Indian and Alaska Native; Asian',\n",
    "           'Total!!Two or More Races!!Population of three races!!Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
    "           'Total!!Two or More Races!!Population of three races!!Black or African American; American Indian and Alaska Native; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of three races!!Black or African American; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "           'Total!!Two or More Races!!Population of three races!!Black or African American; Asian; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of three races!!Black or African American; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of three races!!American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "           'Total!!Two or More Races!!Population of three races!!American Indian and Alaska Native; Asian; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of three races!!American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of three races!!Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of four races!!White; Black or African American; American Indian and Alaska Native; Asian',\n",
    "           'Total!!Two or More Races!!Population of four races!!White; Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
    "           'Total!!Two or More Races!!Population of four races!!White; Black or African American; American Indian and Alaska Native; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of four races!!White; Black or African American; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "           'Total!!Two or More Races!!Population of four races!!White; Black or African American; Asian; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of four races!!White; Black or African American; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of four races!!White; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "           'Total!!Two or More Races!!Population of four races!!White; American Indian and Alaska Native; Asian; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of four races!!White; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of four races!!White; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of four races!!Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "           'Total!!Two or More Races!!Population of four races!!Black or African American; American Indian and Alaska Native; Asian; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of four races!!Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of four races!!Black or African American; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of four races!!American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of five races!!White; Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "           'Total!!Two or More Races!!Population of five races!!White; Black or African American; American Indian and Alaska Native; Asian; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of five races!!White; Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of five races!!White; Black or African American; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of five races!!White; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of five races!!Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of six races!!White; Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race']\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find races that are <10% in dataset\n",
    "\n",
    "def get_minor_swapping(county, file, column):\n",
    "    df_orig = pd.read_csv (r'../homemade_data/'+county+'.csv')\n",
    "    df_orig = df_orig.loc[:, ~df_orig.columns.str.contains('^Unnamed')]\n",
    "    df_orig = df_orig.loc[:, ~df_orig.columns.str.contains('SwapVal')]\n",
    "    for index, row in df_orig.iterrows():\n",
    "        d = row['race']\n",
    "        h = row['hispanic']\n",
    "        if d in races and h==1:\n",
    "            df_orig.at[index, 'race'] = races.index(d)\n",
    "        elif d in races and h==0:\n",
    "            df_orig.at[index, 'race'] = races.index(d)+63\n",
    "    labels_all = []\n",
    "    vals_all = []\n",
    "\n",
    "    #get list of occurrences by race - orig\n",
    "    for key1, value1 in df_orig.iteritems():\n",
    "        if(key1 == column):\n",
    "            labs, vals = zip(*Counter(value1).items())\n",
    "            labs = list(labs)\n",
    "            vals = list(vals)\n",
    "            for i in range(0, len(real_order)):\n",
    "                if i not in labs:\n",
    "                    labels_all.append(i)\n",
    "                    vals_all.append(0)\n",
    "                elif i in labs:\n",
    "                    pos = labs.index(i)\n",
    "                    labels_all.append(i)\n",
    "                    vals_all.append(vals[pos])   \n",
    "    labels_all = np.arange(0,len(real_order),1)\n",
    "\n",
    "    \n",
    "    #get list of occurences by race - swapping\n",
    "    df2 = pd.read_csv(file)\n",
    "    for index, row in df2.iterrows():\n",
    "        d = row['race']\n",
    "        h = row['hispanic']\n",
    "        if h==0:\n",
    "            df2.at[index, 'race'] = d+63\n",
    "    labels2_all = []\n",
    "    vals2_all = []\n",
    "    \n",
    "    for key, value in df2.iteritems():\n",
    "        if(key == column):\n",
    "            labels2, values2 = zip(*Counter(value).items())\n",
    "            labels2=list(labels2)\n",
    "            values2 = list(values2)\n",
    "            for i in range(0, len(real_order)):\n",
    "                if i not in labels2:\n",
    "                    labels2_all.append(i)\n",
    "                    vals2_all.append(0)\n",
    "                elif i in labels2:\n",
    "                    pos = labels2.index(i)\n",
    "                    labels2_all.append(i)\n",
    "                    vals2_all.append(values2[pos])\n",
    "    labels2_all = np.arange(0,len(real_order),1)\n",
    "    \n",
    "    \n",
    "    #get percent race occurrences of each race in original data (only calculate for minorites >5%)\n",
    "    total = 0\n",
    "    for e in range(0, len(vals_all)):\n",
    "        total = total + vals_all[e]\n",
    "    final = []\n",
    "    for i in range(0,len(vals_all)):\n",
    "        if vals_all[i]/total <= 0.1:\n",
    "            final.append(i)\n",
    "            \n",
    "    summy = 0\n",
    "    for f in final:\n",
    "        summy += vals_all[f]\n",
    "    \n",
    "    #find mean difference for all minority groups\n",
    "    differences = []\n",
    "    for idx in final:\n",
    "        if (vals2_all[idx]-vals_all[idx]) < 0:\n",
    "            differences.append(abs((vals2_all[idx]-vals_all[idx]))/(vals_all[idx]+1))\n",
    "    differences.sort()\n",
    "    \n",
    "    if(len(differences)>0):\n",
    "        mean = sum(differences)/len(differences)\n",
    "    else:\n",
    "        mean = 0\n",
    "        \n",
    "\n",
    "    return mean\n",
    "            \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alameda\n",
      "291\n",
      "291\n",
      "291\n",
      "0.01 0.01\n",
      "0.060000000000000005 0.060000000000000005\n",
      "0.11 0.11\n"
     ]
    }
   ],
   "source": [
    "def similar_mean_dif(county):\n",
    "    dfinal = pd.DataFrame(columns=['filename', 'mean_difference'])\n",
    "\n",
    "    for filename in os.listdir('../swapping/swap_runs3/'+county+'/similar/'):\n",
    "            if filename.endswith(\".csv\"):\n",
    "                meandif = get_minor_swapping(county, '../swapping/swap_runs3/'+county+'/similar/'+filename, 'race')\n",
    "                \n",
    "                dfinal = dfinal.append({'filename': filename, 'mean_difference': meandif}, ignore_index=True)\n",
    "                \n",
    "    swaprates = np.arange(.01, .15, .05, float)\n",
    "    \n",
    "    sorted = {}\n",
    "    for s in swaprates:\n",
    "        #meandif, count\n",
    "        sorted[s] = []\n",
    "   \n",
    "    for column_name, data in dfinal.iterrows():\n",
    "        f = data[0].rfind('_')\n",
    "        swap = data[0][0:f]\n",
    "        swap = swap[5:]\n",
    "        \n",
    "        for s in swaprates:\n",
    "            spos = str(s)[0:f]\n",
    "            if swap == spos:           \n",
    "                sorted[s].append(data[1])\n",
    "                break\n",
    "    \n",
    "    for s in swaprates:\n",
    "        sorted[s] = sum(sorted[s])/len(sorted[s])\n",
    "                \n",
    "    final = pd.DataFrame(columns=['filename', 'mean_difference'])\n",
    "    for s in sorted:\n",
    "        final = final.append({'filename': s, 'mean_difference': sorted[s]}, ignore_index=True)\n",
    "                \n",
    "        \n",
    "    \n",
    "    fa = \"mean_dif/\"+county+\"/similar/swapping_final.csv\"\n",
    "    csv_orig_data = final.to_csv(fa, index = True)\n",
    "\n",
    "    \n",
    "counties = ['Alameda', 'Armstrong', 'Cibola', 'Fayette', 'GrandForks', 'Hawaii', 'Jefferson', 'Nantucket', 'Washington']\n",
    "counties = ['alameda']\n",
    "for county in counties:\n",
    "    print(county)\n",
    "    similar_mean_dif(county)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minor_dp(county, file, column):\n",
    "    df_orig = pd.read_csv (r'../homemade_data/'+county+'.csv')\n",
    "    df_orig = df_orig.loc[:, ~df_orig.columns.str.contains('^Unnamed')]\n",
    "    df_orig = df_orig.loc[:, ~df_orig.columns.str.contains('SwapVal')]\n",
    "    for index, row in df_orig.iterrows():\n",
    "        d = row['race']\n",
    "        h = row['hispanic']\n",
    "        if d in races and h==1:\n",
    "            df_orig.at[index, 'race'] = races.index(d)\n",
    "        elif d in races and h==0:\n",
    "            df_orig.at[index, 'race'] = races.index(d)+63\n",
    "    labels_all = []\n",
    "    vals_all = []\n",
    "\n",
    "    #get list of occurrences by race - orig\n",
    "    for key1, value1 in df_orig.iteritems():\n",
    "        if(key1 == column):\n",
    "            labs, vals = zip(*Counter(value1).items())\n",
    "            labs = list(labs)\n",
    "            vals = list(vals)\n",
    "            for i in range(0, len(real_order)):\n",
    "                if i not in labs:\n",
    "                    labels_all.append(i)\n",
    "                    vals_all.append(0)\n",
    "                elif i in labs:\n",
    "                    pos = labs.index(i)\n",
    "                    labels_all.append(i)\n",
    "                    vals_all.append(vals[pos])   \n",
    "    labels_all = np.arange(0,len(real_order),1)\n",
    "\n",
    "    #get list of occurences by race - swapping\n",
    "    df2 = pd.read_csv(file)\n",
    "    for index, row in df2.iterrows():\n",
    "        d = row['race']\n",
    "        h = row['hispanic']\n",
    "        if h==0:\n",
    "            i = races.index(d)\n",
    "            df2.at[index, 'race'] = i+63\n",
    "        else:\n",
    "            i= races.index(d)\n",
    "            df2.at[index, 'race'] = i\n",
    "    labels2_all = []\n",
    "    vals2_all = []\n",
    "\n",
    "    \n",
    "    for key, value in df2.iteritems():\n",
    "        if(key == column):\n",
    "            labels2, values2 = zip(*Counter(value).items())\n",
    "            labels2=list(labels2)\n",
    "            values2 = list(values2)\n",
    "            for i in range(0, len(real_order)):\n",
    "                if i not in labels2:\n",
    "                    labels2_all.append(i)\n",
    "                    vals2_all.append(0)\n",
    "                elif i in labels2:\n",
    "                    pos = labels2.index(i)\n",
    "                    labels2_all.append(i)\n",
    "                    vals2_all.append(values2[pos])\n",
    "    labels2_all = np.arange(0,len(real_order),1)\n",
    "\n",
    "    \n",
    "    #get percent race occurrences of each race in original data (only calculate for minorites >5%)\n",
    "    total = 0\n",
    "    for e in range(0, len(vals_all)):\n",
    "        total = total + vals_all[e]\n",
    "    final = []\n",
    "    for i in range(0,len(vals_all)):\n",
    "        if vals_all[i]/total <= 0.1:\n",
    "            final.append(i)\n",
    "            \n",
    "    summy = 0\n",
    "    for f in final:\n",
    "        summy += vals_all[f]\n",
    "    \n",
    "    #find mean difference for all minority groups\n",
    "    differences = []\n",
    "    for idx in final:\n",
    "        if (vals2_all[idx]-vals_all[idx]) < 0:\n",
    "            differences.append(abs((vals2_all[idx]-vals_all[idx]))/(vals_all[idx]+1))\n",
    "    differences.sort()\n",
    "    \n",
    "    if(len(differences)>0):\n",
    "        mean = sum(differences)/len(differences)\n",
    "    else:\n",
    "        mean = 0\n",
    "        \n",
    "\n",
    "    return mean\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alameda\n",
      "dprun_1.0_0.csv\n",
      "dprun_2.0_0.csv\n",
      "dprun_3.0_0.csv\n",
      "dprun_4.0_0.csv\n",
      "dprun_5.0_0.csv\n",
      "dprun_6.0_0.csv\n",
      "orig_data.csv\n"
     ]
    }
   ],
   "source": [
    "def dp_mean_dif(county):\n",
    "    \n",
    "    ep = np.arange(1, 7, 1, float)\n",
    "    \n",
    "    epsilon = []\n",
    "    \n",
    "    for ee in ep:\n",
    "        ee = str(round(ee,1))\n",
    "        if ee[len(ee)-1] == '.':\n",
    "            ee = str(e)+'0'\n",
    "        epsilon.append(ee)\n",
    "\n",
    "    \n",
    "    dfinal = pd.DataFrame(columns=['filename', 'mean_difference'])\n",
    "\n",
    "    for filename in os.listdir('../dp/dp_runs/'+county+'/'):\n",
    "            if filename.endswith(\".csv\"):\n",
    "                print(filename)\n",
    "                meandif = get_minor_dp(county, '../dp/dp_runs/'+county+'/'+filename, 'race')\n",
    "                \n",
    "                dfinal = dfinal.append({'filename': filename, 'mean_difference': meandif}, ignore_index=True)\n",
    "                \n",
    "    \n",
    "       \n",
    "    sorted = {}\n",
    "    for e in epsilon:\n",
    "        #meandif, count\n",
    "        sorted[e] = []\n",
    "\n",
    "    for column_name, data in dfinal.iterrows():\n",
    "        f = data[0].rfind('_')\n",
    "        swap = data[0][0:f]\n",
    "        swap = swap[6:]\n",
    "        \n",
    "        \n",
    "        for e in epsilon:\n",
    "            if swap[:3] == e[:3]: \n",
    "                sorted[e].append(data[1])\n",
    "                break\n",
    "            #print(sorted[s])\n",
    "    \n",
    "    for e in epsilon:\n",
    "        sorted[e] = sum(sorted[e])/len(sorted[e])\n",
    "                \n",
    "    final = pd.DataFrame(columns=['filename', 'mean_difference'])\n",
    "    for e in sorted:\n",
    "        final = final.append({'filename': e, 'mean_difference': sorted[e]}, ignore_index=True)\n",
    "                \n",
    "\n",
    "    fa = \"mean_dif/\"+county+\"/dp/dp.csv\"\n",
    "    csv_orig_data = final.to_csv(fa, index = True)\n",
    "\n",
    "    \n",
    "counties = ['Alameda', 'Armstrong', 'Cibola', 'Fayette', 'GrandForks', 'Hawaii', 'Jefferson', 'Nantucket', 'Washington']\n",
    "counties = ['alameda']\n",
    "for county in counties:\n",
    "    print(county)\n",
    "    dp_mean_dif(county)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
