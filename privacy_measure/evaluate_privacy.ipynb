{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import math\n",
    "\n",
    "#retrieve race keys\n",
    "%store -r races\n",
    "%store -r races2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################################################\n",
    "#CREATE_DATA: LOAD IN DATASET\n",
    "###########################################################################################################################\n",
    "# INPUT: \n",
    "#      path: path csv containing block data\n",
    "#      age_buckets: value for number of items in each age bucket\n",
    "\n",
    "#  -reads in csv file to pandas dataframe\n",
    "#  -replaces race string with equivalent ints 0-63 race if applicable\n",
    "#  -replaces ages with appropriate age bucket labels if applicable\n",
    "\n",
    "# OUTPUT: dataframe containing dataset with modified age and race values\n",
    "##########################################################################################################################\n",
    "\n",
    "def create_data(path, age_groupsize, max_age):\n",
    "    #import original data\n",
    "    df_orig = pd.read_csv (path)\n",
    "    df_orig = df_orig.loc[:, ~df_orig.columns.str.contains('^Unnamed')]\n",
    "    \n",
    "    #adjust values of necessary\n",
    "    for index, row in df_orig.iterrows():    \n",
    "        \n",
    "        #RACE\n",
    "        d = row['race']\n",
    "        h = row['hispanic']\n",
    "        #replace race w/ value 0-63\n",
    "        if d in races:\n",
    "            df_orig.at[index, 'race'] = races.index(d)\n",
    "        elif d in races2:\n",
    "            df_orig.at[index, 'race'] = races2.index(d)        \n",
    "            \n",
    "        #AGE\n",
    "        #if age buckets are implemented:\n",
    "        if age_groupsize > 1: \n",
    "            a = row['age']\n",
    "            #get number of times groupsize goes into age:\n",
    "            #ex. get new value for 12 with a group size of 5:\n",
    "            #    12/5 = 2 w/remainder of 3 --> would return 2\n",
    "            #set value in original dataset to this age bucket value\n",
    "            df_orig.at[index, 'age'] = np.floor(a/age_groupsize)\n",
    "                 \n",
    "    return df_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################################################\n",
    "#CREATE ATTRIBUTE COMBOS TO LOOK FOR IN DATASETS\n",
    "###########################################################################################################################\n",
    "#INPUT:\n",
    "#     age_range: all possible values for age\n",
    "#     race_range: all possible values for race\n",
    "#     size_range: all possible values for household_size\n",
    "\n",
    "#  -create all possible combos of age, race, household size\n",
    "\n",
    "#OUTPUT:\n",
    "#  -M: list containing all age, race, household size combos\n",
    "###########################################################################################################################\n",
    "\n",
    "def create_combos(age_range, race_range, size_range):\n",
    "    \n",
    "    #list containing all age, race, household size combos\n",
    "    M = []\n",
    "    \n",
    "    #create all combos; append to M\n",
    "    for age in age_range:\n",
    "            for race in race_range:\n",
    "                for size in size_range:\n",
    "                    M.append([age, race, size])\n",
    "                    \n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################################################\n",
    "#FIND UNIQUE ROWS\n",
    "###########################################################################################################################\n",
    "#INPUT:\n",
    "#     M: set of attributes shared between D and P ['age', 'race', 'household_size']\n",
    "#     D: dataframe to search for unique rows\n",
    "#     theta_d: attribute set size limit in D. we only examine attribute tuples with at most theta_d matching entries in D\n",
    "\n",
    "#  -get how many times each attribute combination occurs in the dataframe\n",
    "#  -if only occurs once, add id to unique list; if occurs under the given theta_d threshold, add id to under_threshold list\n",
    "#  -return these lists of rows that are unique or under threshold \n",
    "\n",
    "#OUTPUT:\n",
    "#  -unique: list of ids of rows that are unique for (age, race, household_size) in the dataset\n",
    "#  -under_threshold: list of ids of rows that are under the given occurence threshold in the dataset\n",
    "###########################################################################################################################\n",
    "    \n",
    "def get_unique_rows(M, D, theta_d):\n",
    "\n",
    "    #vals to be returned:\n",
    "    #1. unique rows in D \n",
    "    unique = []\n",
    "    #2. those under theta_d threshold\n",
    "    under_threshold = []\n",
    "   \n",
    "    #for attribute combination in M\n",
    "    for row in M:   \n",
    "        \n",
    "        #true case - get how many times that the attribute combination occurs in the deidentified dataset \n",
    "        att_val_combos = D.loc[(D['age'] == row[0]) & (D['race'] == row[1]) & (D['household_size'] == row[2])]\n",
    "        \n",
    "        #if combo occurs at least once and less than threshold in deidentified dataset\n",
    "        if len(att_val_combos) <= theta_d and len(att_val_combos) > 0:\n",
    "            #add IDs to under_threshold list\n",
    "            for index, row in att_val_combos.iterrows():\n",
    "                under_threshold.append([row['id'], [row['age'], row['race'], row['household_size']]])\n",
    "            \n",
    "        if len(att_val_combos) == 1:\n",
    "            #add IDs to unique list\n",
    "            for index, row in att_val_combos.iterrows():\n",
    "                unique.append([row['id'], [row['age'], row['race'], row['household_size']]])\n",
    "    \n",
    "    return unique, under_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################################################\n",
    "#FIND ROW MATCHES\n",
    "###########################################################################################################################\n",
    "#INPUT:\n",
    "#     public_dataset: publically published dataset\n",
    "#     P_unique: ids of unique rows in public dataset\n",
    "#     de_id_dataset: deidentified dataset\n",
    "#     D_unique: ids of unique rows in de-identified dataset\n",
    "\n",
    "#  -find all unique rows with matching row values\n",
    "#  -return ids of matches\n",
    "\n",
    "#OUTPUT:\n",
    "#     matches: list of ids of all matching unique values [id in public, id in de_id]\n",
    "###########################################################################################################################\n",
    "def find_matches(P_unique, D_unique):\n",
    "    \n",
    "    #create list of unique row values only\n",
    "    D_unique_rows = []\n",
    "    for d in D_unique:\n",
    "        D_unique_rows.append(d[1])\n",
    "        \n",
    "    #LIST OF ROWS WITH MATCHES\n",
    "    matches = []\n",
    "    \n",
    "    #for each row in P_unique, see if there's a matching row in D_unique\n",
    "    for p_row in P_unique:\n",
    "        #see if values of [age, race, sex] associated with unique row in p (p_row) are also a unique row in D\n",
    "        if p_row[1] in D_unique_rows:\n",
    "            # if so, find associated ID\n",
    "            for d_row in D_unique:\n",
    "                if d_row[1] == p_row[1]:\n",
    "                    matches.append([p_row[0], d_row[0]])\n",
    "                    \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################################################\n",
    "#CHECK VALIDITY OF MATCHES\n",
    "###########################################################################################################################\n",
    "#INPUT:\n",
    "#     public_dataset: publically published dataset\n",
    "#     de_id_dataset: deidentified dataset\n",
    "#     matches: list of ids of all matching unique values [id in public, id in de_id]\n",
    "#     minority_races: list containing minority races for county \n",
    "\n",
    "#  -for each match, check if var predicted is the same, and if vars are the same\n",
    "\n",
    "#OUTPUT:\n",
    "#     correct_matches: matches with same id (meaning the same person's data)\n",
    "#     correct_values: all reported matches that had same values (not necessarily an exact ID match)\n",
    "###########################################################################################################################\n",
    "\n",
    "\n",
    "def check_true_vals(matches, public_dataset, de_id_dataset, minority_races):\n",
    "    correct_matches = []\n",
    "    correct_values = []\n",
    "    correct_matches_minority = []\n",
    "    correct_values_minority = []\n",
    "    \n",
    "    #for each match\n",
    "    for match in matches:\n",
    "        \n",
    "        #get values for p_id and d_id\n",
    "        p_id = match[0]\n",
    "        d_id = match[1]\n",
    "        \n",
    "        #get row values are all the same for p_id row and d_id row\n",
    "        p_row = public_dataset.loc[public_dataset['id'] == d_id]\n",
    "        d_row = de_id_dataset.loc[de_id_dataset['id'] == p_id]\n",
    "        #check if all relevant column values match for p_id and d_id rows\n",
    "        if ((p_row.iloc[0]['hispanic']==d_row.iloc[0]['hispanic'])):\n",
    "            #if all values match, add to correct_values\n",
    "            correct_values.append(match)\n",
    "            if p_row.iloc[0]['race'] in minority_races:\n",
    "                correct_values_minority.append(match)\n",
    "        if p_row.iloc[0]['id']==d_row.iloc[0]['id']:\n",
    "            #if ids match, add to correct_matches\n",
    "            correct_matches.append(match)   \n",
    "            if p_row.iloc[0]['race'] in minority_races:\n",
    "                correct_matches_minority.append(match)\n",
    "    \n",
    "    return correct_matches, correct_values, correct_matches_minority, correct_values_minority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_privacy(attribute_ranges, original_data_path, minority_races, de_id_data_directory, age_groupsize, theta_d, k1, k2):\n",
    "    \n",
    "    correct = []\n",
    "    total = []\n",
    "    correct_minority = []\n",
    "    total_minority = []\n",
    "    \n",
    "    #create list of all combinations of attributes that could be present in either the public or de-identified dataset\n",
    "    attribute_combos = create_combos(attribute_ranges[0], attribute_ranges[1], attribute_ranges[2])\n",
    "\n",
    "    #create public dataset\n",
    "    public_dataset = create_data(original_data_path, age_groupsize, len(attribute_ranges[0])-1)\n",
    "        \n",
    "    #find unique rows in public dataset\n",
    "    P_unique, P_under_threshold = get_unique_rows(attribute_combos, public_dataset, theta_d)\n",
    "    \n",
    "    #these are the swap rates to run privacy analysis on\n",
    "    swaprates = np.arange(k1, k2, .01, float).tolist()\n",
    "    \n",
    "    #for each de-id in given directory:\n",
    "    for swaprate in swaprates:\n",
    "        \n",
    "        correct_matches_all =[]\n",
    "        total_matches_all = []\n",
    "        correct_matches_minority_all =[]\n",
    "        total_matches_minority_all = []\n",
    "        \n",
    "        #for all de-id files in directory:\n",
    "        for filename in os.listdir(de_id_data_directory):\n",
    "            \n",
    "            #check if file is a match for the given swaprate:\n",
    "            swap_file = filename[(filename.find(\"_\"))+1:filename.rfind(\"_\")]\n",
    "            \n",
    "            #if match:\n",
    "            if filename.endswith(\".csv\") and math.isclose(float(swaprate), float(swap_file)):\n",
    "                \n",
    "                #create deid-ed dataset \n",
    "                de_id_dataset = create_data(de_id_data_directory+filename, age_groupsize, len(attribute_ranges[0])-1)\n",
    "                \n",
    "                #find unique rows in de-ided\n",
    "                D_unique, D_under_threshold = get_unique_rows(attribute_combos, de_id_dataset, theta_d)\n",
    "\n",
    "                #find matches for unique rows\n",
    "                matches = find_matches(P_unique, D_unique)\n",
    "\n",
    "                #use ID to check true values (predict var & see if var is correct)\n",
    "                correct_matches, total_matches, correct_matches_minority, total_matches_minority = check_true_vals(matches, public_dataset, de_id_dataset, minority_races)\n",
    "\n",
    "                #add to long result list for given swaprate \n",
    "                correct_matches_all.append(len(correct_matches))\n",
    "                total_matches_all.append(len(total_matches))\n",
    "                correct_matches_minority_all.append(len(correct_matches_minority))\n",
    "                total_matches_minority_all.append(len(total_matches_minority))\n",
    "        \n",
    "        \n",
    "        #get average value for each swap rate\n",
    "        print(correct_matches_all)\n",
    "        print(correct_matches_minority_all)\n",
    "        #sum values for total:\n",
    "        #format: [match value, # of runs at swaprate]\n",
    "        correct_matches_total = [0,0]\n",
    "        total_matches_total = [0,0]\n",
    "        #sum values for minority groups:\n",
    "        #format: [match value, # of runs at swaprate]\n",
    "        correct_matches_minority_total = [0,0]\n",
    "        total_matches_minority_total = [0,0]\n",
    "        \n",
    "        for s in correct_matches_all:\n",
    "            correct_matches_total[0] = correct_matches_total[0] + s\n",
    "            correct_matches_total[1] = correct_matches_total[1] + 1\n",
    "\n",
    "        for s in total_matches_all:\n",
    "            total_matches_total[0] = total_matches_total[0] + s\n",
    "            total_matches_total[1] = total_matches_total[1] + 1\n",
    "            \n",
    "        for s in correct_matches_minority_all:\n",
    "            correct_matches_minority_total[0] = correct_matches_minority_total[0] + s\n",
    "            correct_matches_minority_total[1] = correct_matches_minority_total[1] + 1\n",
    "\n",
    "        for s in total_matches_minority_all:\n",
    "            total_matches_minority_total[0] = total_matches_minority_total[0] + s\n",
    "            total_matches_minority_total[1] = total_matches_minority_total[1] + 1\n",
    "            \n",
    "            \n",
    "        #find average value (sum divided by # of values)\n",
    "        corr_matches = correct_matches_total[0]/correct_matches_total[1]\n",
    "        tot_matches = total_matches_total[0]/total_matches_total[1]\n",
    "        corr_minority_matches = correct_matches_minority_total[0]/correct_matches_minority_total[1]\n",
    "        tot_minority_matches = total_matches_minority_total[0]/total_matches_minority_total[1]\n",
    "        \n",
    "        correct.append([swaprate, corr_matches])\n",
    "        total.append([swaprate, tot_matches])\n",
    "        correct_minority.append([swaprate, corr_minority_matches])\n",
    "        total_minority.append([swaprate, tot_minority_matches])\n",
    "        \n",
    "        \n",
    "        print([swaprate, corr_matches], [swaprate, tot_matches], [swaprate, corr_minority_matches], [swaprate, tot_minority_matches])\n",
    "    \n",
    "    return correct, total, correct_minority, total_minority\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23, 28, 27]\n",
      "[20, 22, 21]\n",
      "[0.01, 26.0] [0.01, 26.333333333333332] [0.01, 21.0] [0.01, 21.0]\n",
      "[25, 27, 27]\n",
      "[19, 21, 21]\n",
      "[0.02, 26.333333333333332] [0.02, 26.333333333333332] [0.02, 20.333333333333332] [0.02, 20.333333333333332]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b9ae3e790899>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mstop_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mrunner_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswapping_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroupsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malameda_minority_races\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-b9ae3e790899>\u001b[0m in \u001b[0;36mrunner_function\u001b[0;34m(county, swapping_directory_type, age_groupsize, theta_d, start_rate, stop_rate, minority_races)\u001b[0m\n\u001b[1;32m      5\u001b[0m     correct, total, minority_correct, minority_total = evaluate_privacy(attribute_ranges, '../homemade_data/' + county + '.csv', minority_races,\n\u001b[1;32m      6\u001b[0m                  \u001b[0;34m'../swapping/swap_runs/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcounty\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mswapping_directory_type\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                  age_groupsize, theta_d, start_rate, stop_rate)\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounty\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mswapping_directory_type\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mage_groupsize\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_privacy.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total Correct Matches:\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-e17ba83ca936>\u001b[0m in \u001b[0;36mevaluate_privacy\u001b[0;34m(attribute_ranges, original_data_path, minority_races, de_id_data_directory, age_groupsize, theta_d, k1, k2)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0;31m#find unique rows in de-ided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                 \u001b[0mD_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD_under_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_unique_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattribute_combos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mde_id_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0;31m#find matches for unique rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-da503327e17f>\u001b[0m in \u001b[0;36mget_unique_rows\u001b[0;34m(M, D, theta_d)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m#true case - get how many times that the attribute combination occurs in the deidentified dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0matt_val_combos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'age'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'race'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'household_size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m#if combo occurs at least once and less than threshold in deidentified dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomparison_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_construct_result\u001b[0;34m(self, result, name)\u001b[0m\n\u001b[1;32m   2768\u001b[0m         \u001b[0;31m# We do not pass dtype to ensure that the Series constructor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2769\u001b[0m         \u001b[0;31m#  does inference in the case where `result` has object-dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2770\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2771\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mfrom_array\u001b[0;34m(cls, array, index)\u001b[0m\n\u001b[1;32m   1576\u001b[0m         \u001b[0mConstructor\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mwe\u001b[0m \u001b[0mhave\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0myet\u001b[0m \u001b[0ma\u001b[0m \u001b[0mBlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1577\u001b[0m         \"\"\"\n\u001b[0;32m-> 1578\u001b[0;31m         \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1579\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype)\u001b[0m\n\u001b[1;32m   2735\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mklass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2736\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2737\u001b[0;31m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_block_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2739\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mklass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mDatetimeTZBlock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mget_block_type\u001b[0;34m(values, dtype)\u001b[0m\n\u001b[1;32m   2701\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2702\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatetimeTZBlock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2703\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mis_interval_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_period_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2704\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mObjectValuesExtensionBlock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2705\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#RUNNER FUNCTION\n",
    "\n",
    "def runner_function(county, swapping_directory_type, age_groupsize, theta_d, start_rate, stop_rate, minority_races):\n",
    "    attribute_ranges = [range(int(90/age_groupsize)), range(len(races)), [1,2,3,4]]\n",
    "    correct, total, minority_correct, minority_total = evaluate_privacy(attribute_ranges, '../homemade_data/' + county + '.csv', minority_races,\n",
    "                 '../swapping/swap_runs/'+county+'/'+swapping_directory_type+'/',\n",
    "                 age_groupsize, theta_d, start_rate, stop_rate)\n",
    "    with open(county+\"_\"+swapping_directory_type+\"_\"+age_groupsize+'_privacy.txt', \"a\") as f:\n",
    "        f.write(\"Total Correct Matches:\\n\\n\")\n",
    "        for c in correct:\n",
    "            f.write(c + \"\\n\")\n",
    "        f.write(\"Total Value Matches:\\n\\n\")\n",
    "        for t in total:\n",
    "            f.write(t + \"\\n\")\n",
    "        f.write(\"Minority Correct Matches:\\n\\n\")\n",
    "        for c in minority_correct:\n",
    "            f.write(c + \"\\n\")\n",
    "        f.write(\"Minority Value Matches:\\n\\n\")\n",
    "        for t in minority_total:\n",
    "            f.write(t + \"\\n\")\n",
    "            \n",
    "\n",
    "#WILL NEED TO ADJUST THIS FROM COUNTY TO COUNTY\n",
    "alameda_minority_races = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62]\n",
    "\n",
    "\n",
    "            \n",
    "#UNCOMMENT THIS FOR VMS\n",
    "# county = str(sys.argv[1])\n",
    "# swapping_type = str(sys.arg[2])\n",
    "# groupsize = int((sys.argv[3]))\n",
    "# theta_d = int((sys.argv[4]))\n",
    "# start_rate = float((sys.argv[5]))\n",
    "# stop_rate = float ((sys.argv[6]))\n",
    "\n",
    "\n",
    "#COMMENT THIS OUT FOR VMS\n",
    "county = 'alameda'\n",
    "swapping_type = 'similar_3'\n",
    "groupsize = 15\n",
    "theta_d = 3\n",
    "start_rate = .01\n",
    "stop_rate = 1.0\n",
    "\n",
    "runner_function(county, swapping_type, groupsize, theta_d, start_rate, stop_rate, alameda_minority_races)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
