{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now analyzing  Alameda\n",
      "swap rate: 0.9600000000000001\n",
      "0.9600000000000001 swap_0.9600000000000001_a0.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_a15.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_aaa15.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_aaa16.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_aaa17.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_aaa18.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_aaa19.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_aaa20.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_b0.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_b10.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_c0.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_c15.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_d0.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_d15.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_e0.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_e15.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_f0.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_f15.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_g0.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_g15.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_h0.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_h15.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_i0.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_i15.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_j0.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_j15.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_k0.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_k15.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_l0.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_l15.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_m15.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_n15.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_o15.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_p15.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_q15.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_r15.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_s15.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_a0.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_a1.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_a10.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_a11.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_a12.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_a13.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_a14.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_a15.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_a16.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_a17.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_a18.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_a19.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_a2.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_a20.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_a3.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_a4.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_a5.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_a6.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_a7.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_a8.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_a9.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_b0.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_b1.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_b10.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_b11.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_b12.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_b13.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_b14.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_b15.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_b16.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_b17.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_b18.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_b19.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_b2.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_b3.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_b4.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_b5.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_b6.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_b7.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_b8.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_b9.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_c0.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_c1.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_c10.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_c11.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_c12.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_c13.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_c14.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_c15.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_c16.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_c17.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_c18.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_c19.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_c2.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_c20.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_c3.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_c4.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_c5.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_c6.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_c7.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_c8.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_c9.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_d0.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_d1.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_d10.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_d11.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_d12.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_d13.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_d14.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_d15.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_d16.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_d17.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_d18.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_d19.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_d2.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_d3.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_d4.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_d5.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_d6.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_d7.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_d8.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_d9.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_e0.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_e1.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_e10.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_e11.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_e12.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_e13.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_e14.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_e15.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_e16.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_e17.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_e18.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_e19.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_e2.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_e3.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_e4.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_e5.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_e6.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_e7.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_e8.csv\n",
      "0.9600000000000001 swap_0.9600000000000001_e9.csv\n",
      "['0.9600000000000001', 12.35135135135135, 6.648648648648648]\n",
      "['0.9600000000000001', 21.61764705882353, 8.009803921568627]\n",
      "[['0.9600000000000001', 12.35135135135135, 6.648648648648648]] [['0.9600000000000001', 21.61764705882353, 8.009803921568627]]\n",
      "Alameda  similar:\n",
      "[['0.9600000000000001', 12.35135135135135, 6.648648648648648]]\n",
      "Alameda  random:\n",
      "[['0.9600000000000001', 21.61764705882353, 8.009803921568627]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "races = ['White alone',\n",
    "         'Black or African American alone',\n",
    "         'American Indian and Alaska Native alone',\n",
    "         'Asian alone',\n",
    "         'Native Hawaiian and Other Pacific Islander alone',\n",
    "         'Some Other Race alone',\n",
    "         'White; Black or African American',\n",
    "         'White; American Indian and Alaska Native',\n",
    "         'White; Asian',\n",
    "         'White; Native Hawaiian and Other Pacific Islander',\n",
    "         'White; Some Other Race',\n",
    "         'Black or African American; American Indian and Alaska Native',\n",
    "         'Black or African American; Asian',\n",
    "         'Black or African American; Native Hawaiian and Other Pacific Islander',\n",
    "         'Black or African American; Some Other Race',\n",
    "         'American Indian and Alaska Native; Asian',\n",
    "         'American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
    "         'American Indian and Alaska Native; Some Other Race',\n",
    "         'Asian; Native Hawaiian and Other Pacific Islander',\n",
    "         'Asian; Some Other Race',\n",
    "         'Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "         'White; Black or African American; American Indian and Alaska Native',\n",
    "         'White; Black or African American; Asian',\n",
    "         'White; Black or African American; Native Hawaiian and Other Pacific Islander',\n",
    "         'White; Black or African American; Some Other Race',\n",
    "         'White; American Indian and Alaska Native; Asian',\n",
    "         'White; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
    "         'White; American Indian and Alaska Native; Some Other Race',\n",
    "         'White; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "         'White; Asian; Some Other Race',\n",
    "         'White; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "         'Black or African American; American Indian and Alaska Native; Asian',\n",
    "         'Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
    "         'Black or African American; American Indian and Alaska Native; Some Other Race',\n",
    "         'Black or African American; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "         'Black or African American; Asian; Some Other Race',\n",
    "         'Black or African American; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "         'American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "         'American Indian and Alaska Native; Asian; Some Other Race',\n",
    "         'American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "         'Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "         'White; Black or African American; American Indian and Alaska Native; Asian',\n",
    "         'White; Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
    "         'White; Black or African American; American Indian and Alaska Native; Some Other Race',\n",
    "         'White; Black or African American; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "         'White; Black or African American; Asian; Some Other Race',\n",
    "         'White; Black or African American; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "         'White; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "         'White; American Indian and Alaska Native; Asian; Some Other Race',\n",
    "         'White; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "         'White; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "         'Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "         'Black or African American; American Indian and Alaska Native; Asian; Some Other Race',\n",
    "         'Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "         'Black or African American; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "         'American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "         'White; Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "         'White; Black or African American; American Indian and Alaska Native; Asian; Some Other Race',\n",
    "         'White; Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "         'White; Black or African American; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "         'White; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "         'Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "         'White; Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race']\n",
    "\n",
    "races2 = ['Total!!Population of one race!!White alone',\n",
    "          'Total!!Population of one race!!Black or African American alone',\n",
    "          'Total!!Population of one race!!American Indian and Alaska Native alone',\n",
    "          'Total!!Population of one race!!Asian alone',\n",
    "          'Total!!Population of one race!!Native Hawaiian and Other Pacific Islander alone',\n",
    "          'Total!!Population of one race!!Some Other Race alone',\n",
    "          'Total!!Two or More Races!!Population of two races!!White; Black or African American',\n",
    "          'Total!!Two or More Races!!Population of two races!!White; American Indian and Alaska Native',\n",
    "          'Total!!Two or More Races!!Population of two races!!White; Asian',\n",
    "          'Total!!Two or More Races!!Population of two races!!White; Native Hawaiian and Other Pacific Islander',\n",
    "          'Total!!Two or More Races!!Population of two races!!White; Some Other Race',\n",
    "          'Total!!Two or More Races!!Population of two races!!Black or African American; American Indian and Alaska Native',\n",
    "          'Total!!Two or More Races!!Population of two races!!Black or African American; Asian',\n",
    "          'Total!!Two or More Races!!Population of two races!!Black or African American; Native Hawaiian and Other Pacific Islander',\n",
    "          'Total!!Two or More Races!!Population of two races!!Black or African American; Some Other Race',\n",
    "          'Total!!Two or More Races!!Population of two races!!American Indian and Alaska Native; Asian',\n",
    "          'Total!!Two or More Races!!Population of two races!!American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
    "          'Total!!Two or More Races!!Population of two races!!American Indian and Alaska Native; Some Other Race',\n",
    "          'Total!!Two or More Races!!Population of two races!!Asian; Native Hawaiian and Other Pacific Islander',\n",
    "          'Total!!Two or More Races!!Population of two races!!Asian; Some Other Race',\n",
    "          'Total!!Two or More Races!!Population of two races!!Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "          'Total!!Two or More Races!!Population of three races!!White; Black or African American; American Indian and Alaska Native',\n",
    "          'Total!!Two or More Races!!Population of three races!!White; Black or African American; Asian',\n",
    "          'Total!!Two or More Races!!Population of three races!!White; Black or African American; Native Hawaiian and Other Pacific Islander',\n",
    "          'Total!!Two or More Races!!Population of three races!!White; Black or African American; Some Other Race',\n",
    "          'Total!!Two or More Races!!Population of three races!!White; American Indian and Alaska Native; Asian',\n",
    "          'Total!!Two or More Races!!Population of three races!!White; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
    "          'Total!!Two or More Races!!Population of three races!!White; American Indian and Alaska Native; Some Other Race',\n",
    "          'Total!!Two or More Races!!Population of three races!!White; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "          'Total!!Two or More Races!!Population of three races!!White; Asian; Some Other Race',\n",
    "          'Total!!Two or More Races!!Population of three races!!White; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "          'Total!!Two or More Races!!Population of three races!!Black or African American; American Indian and Alaska Native; Asian',\n",
    "          'Total!!Two or More Races!!Population of three races!!Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
    "          'Total!!Two or More Races!!Population of three races!!Black or African American; American Indian and Alaska Native; Some Other Race',\n",
    "          'Total!!Two or More Races!!Population of three races!!Black or African American; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "          'Total!!Two or More Races!!Population of three races!!Black or African American; Asian; Some Other Race',\n",
    "          'Total!!Two or More Races!!Population of three races!!Black or African American; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "          'Total!!Two or More Races!!Population of three races!!American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "          'Total!!Two or More Races!!Population of three races!!American Indian and Alaska Native; Asian; Some Other Race',\n",
    "          'Total!!Two or More Races!!Population of three races!!American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "          'Total!!Two or More Races!!Population of three races!!Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "          'Total!!Two or More Races!!Population of four races!!White; Black or African American; American Indian and Alaska Native; Asian',\n",
    "          'Total!!Two or More Races!!Population of four races!!White; Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
    "          'Total!!Two or More Races!!Population of four races!!White; Black or African American; American Indian and Alaska Native; Some Other Race',\n",
    "          'Total!!Two or More Races!!Population of four races!!White; Black or African American; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "          'Total!!Two or More Races!!Population of four races!!White; Black or African American; Asian; Some Other Race',\n",
    "          'Total!!Two or More Races!!Population of four races!!White; Black or African American; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "          'Total!!Two or More Races!!Population of four races!!White; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "          'Total!!Two or More Races!!Population of four races!!White; American Indian and Alaska Native; Asian; Some Other Race',\n",
    "          'Total!!Two or More Races!!Population of four races!!White; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "          'Total!!Two or More Races!!Population of four races!!White; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "          'Total!!Two or More Races!!Population of four races!!Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "          'Total!!Two or More Races!!Population of four races!!Black or African American; American Indian and Alaska Native; Asian; Some Other Race',\n",
    "          'Total!!Two or More Races!!Population of four races!!Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "          'Total!!Two or More Races!!Population of four races!!Black or African American; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "          'Total!!Two or More Races!!Population of four races!!American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "          'Total!!Two or More Races!!Population of five races!!White; Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "          'Total!!Two or More Races!!Population of five races!!White; Black or African American; American Indian and Alaska Native; Asian; Some Other Race',\n",
    "          'Total!!Two or More Races!!Population of five races!!White; Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "          'Total!!Two or More Races!!Population of five races!!White; Black or African American; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "          'Total!!Two or More Races!!Population of five races!!White; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "          'Total!!Two or More Races!!Population of five races!!Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "          'Total!!Two or More Races!!Population of six races!!White; Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race']\n",
    "\n",
    "#re_id function re-written using pandas operations for massive performance improvements\n",
    "#note this assumes that index keys are the same between the index vals\n",
    "#validated aganist original privacy functions for accuracy\n",
    "def re_id(D, P, M, theta_d, theta_p, indices, swapped):\n",
    "    # D: de-identified dataset\n",
    "    # P: public dataset\n",
    "    # M: set of attributes shared between D and P\n",
    "    # alpha: attribute set size limit in M. we only examine attribute tuples where at most alpha entries in M have that tuple\n",
    "    # we remove alpha here and look at sets of all sizes, since runtime is not an issue\n",
    "    # theta_d: attribute set size limit in D. we only examine attribute tuples with at most theta_d matching entries in D\n",
    "    # theta_p: attribute set size limit in P.\n",
    "    # theta_d, and theta_p are used to limit compute costs. we can set them to |D|\n",
    "    # indices: list of index triples. a triple (i,j, k) indicates that attribute k in M corresponds to attribute i in D and attribute j in P\n",
    "    # paper used alpha=7, theta_d = 10, theta_p = 5\n",
    "    # D, P, and M must have attributes in the same order. matching attributes must come first in D and P\n",
    "    # swapped: indicates whether D was anonymized via swapping\n",
    "    num_vulnerable = 0\n",
    "    num_identified = 0\n",
    "    V = [] #list of vulnerable entries\n",
    "    for row in M:\n",
    "        #true case\n",
    "        att_val_combos = D.loc[(D['age'] == row[0]) &\n",
    "                               (D['race'] == row[1]) &\n",
    "                               (D['household_size'] == row[2])]\n",
    "        if len(att_val_combos) <= theta_d and len(att_val_combos) > 0:\n",
    "            #false case - not using indices in theory fine\n",
    "            p_matches = P.loc[(P['age'] == row[0]) &\n",
    "                                   (P['race'] == row[1]) &\n",
    "                                   (P['household_size'] == row[2])]\n",
    "            if len(p_matches) <= theta_p and len(p_matches) > 0:\n",
    "                if swapped:\n",
    "                    count = att_val_combos[att_val_combos['SwapVal'] == False].shape[0]\n",
    "                    num_vulnerable += count\n",
    "                    if (len(p_matches) == 1):\n",
    "                        num_identified += count\n",
    "                else:\n",
    "                    num_vulnerable += len(p_matches)\n",
    "                    if (len(p_matches) == 1):\n",
    "                        num_identified += len(p_matches)\n",
    "                V.append([row, att_val_combos, p_matches])\n",
    "    return V, num_vulnerable, num_identified\n",
    "\n",
    "\n",
    "##########################################################################################################################\n",
    "# CREATE PUBLIC DATA\n",
    "# input: csv containing block data\n",
    "# output: dataframe containing public dataset with age and sex\n",
    "##########################################################################################################################\n",
    "\n",
    "def create_public_data_age_sex(path, races):\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "    for col_name, data in df.items():\n",
    "        if col_name == 'race':\n",
    "            oof = 0\n",
    "            for d in data:\n",
    "                if d in races:\n",
    "                    df.at[oof, 'race'] = races.index(d)\n",
    "                oof += 1\n",
    "            oof = 0\n",
    "            for d in data:\n",
    "                if d in races2:\n",
    "                    df.at[oof, 'race'] = races2.index(d)\n",
    "                oof += 1\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def measure_privacy(county, races):\n",
    "    # prints privacy value for each swap rate for the given county\n",
    "    swap_rates = ['0.9600000000000001']\n",
    "\n",
    "    indices = [['age', 'age', 0], ['race', 'race', 1], ['household_size', 'household_size', 2]]\n",
    "    # Set up datasets\n",
    "\n",
    "    # Common attributes\n",
    "    M = []\n",
    "    for age in range(90):\n",
    "        for race in range(0, len(races)):\n",
    "            for size in [1, 2, 3, 4]:\n",
    "                M.append([age, race, size])\n",
    "\n",
    "    # Original dataset\n",
    "    P = create_public_data_age_sex('../homemade_data/' + county + '.csv', races)\n",
    "\n",
    "    # create arrays where we will record privacy values\n",
    "    stats1 = []\n",
    "    stats2 = []\n",
    "\n",
    "    # evaluate privacy for datasets of each swap rate\n",
    "    for rate in swap_rates:\n",
    "        #try for all of a given swap rate:        \n",
    "        print('swap rate: ' + str(rate))\n",
    "        srvals1 = []\n",
    "        srvals2 = []\n",
    "        for filename in os.listdir('../swapping/swap_runs/'+county+'/similar/'):\n",
    "            directory = '../swapping/swap_runs/'+county+'/similar/'\n",
    "            if filename.endswith(\".csv\") and (rate in filename):  \n",
    "                print(rate, filename)\n",
    "                D1 = create_public_data_age_sex(directory+filename, races)\n",
    "                V1, num_vulnerable1, num_identified1 = re_id(D1, P, M, 3, 3, indices, True)\n",
    "                srvals1.append([rate, num_vulnerable1, num_identified1])\n",
    "                \n",
    "        srvals1_id_total = [0,0]\n",
    "        srvals1_vul_total = [0,0]\n",
    "        for s in srvals1:\n",
    "            srvals1_id_total[0] = srvals1_id_total[0] + s[2]\n",
    "            srvals1_id_total[1] = srvals1_id_total[1] + 1\n",
    "            srvals1_vul_total[0] = srvals1_vul_total[0] + s[1]\n",
    "            srvals1_vul_total[1] = srvals1_vul_total[1] + 1\n",
    "        id1 = srvals1_id_total[0]/srvals1_id_total[1]\n",
    "        vul1 = srvals1_vul_total[0]/srvals1_vul_total[1]\n",
    "                \n",
    "        for filename in os.listdir('../swapping/swap_runs/'+county+'/random/'):  \n",
    "            directory = '../swapping/swap_runs/'+county+'/random/'\n",
    "            if filename.endswith(\".csv\") and (rate in filename):  \n",
    "                print(rate, filename)\n",
    "                D2 = create_public_data_age_sex(directory+filename, races)\n",
    "                V2, num_vulnerable2, num_identified2 = re_id(D2, P, M, 3, 3, indices, True)\n",
    "                srvals2.append([rate, num_vulnerable2, num_identified2])\n",
    "               \n",
    "        srvals2_id_total = [0,0]  \n",
    "        srvals2_vul_total = [0,0] \n",
    "        for s in srvals2:\n",
    "            srvals2_id_total[0] = srvals2_id_total[0] + s[2]\n",
    "            srvals2_id_total[1] = srvals2_id_total[1] + 1\n",
    "            srvals2_vul_total[0] = srvals2_vul_total[0] + s[1]\n",
    "            srvals2_vul_total[1] = srvals2_vul_total[1] + 1\n",
    "        id2 = srvals2_id_total[0]/srvals2_id_total[1]\n",
    "        vul2 = srvals2_vul_total[0]/srvals2_vul_total[1]\n",
    "                \n",
    "        stats1.append([rate,vul1,id1])\n",
    "        stats2.append([rate,vul2,id2])\n",
    "        print([rate,vul1,id1])\n",
    "        print(([rate,vul2,id2]))\n",
    "    return stats1, stats2\n",
    "\n",
    "counties = ['Washington']\n",
    "lines = []\n",
    "\n",
    "for county in counties:\n",
    "    lines.append(f'\\n\\n{county}\\n----------------------------------------------')\n",
    "    print('now analyzing ', county)\n",
    "    wash1, wash2 = measure_privacy(county, races)\n",
    "    print(wash1, wash2)\n",
    "    print(county, ' similar:')\n",
    "    print(wash1)\n",
    "    lines.append(f'{county} Similar:\\n{wash1}')\n",
    "    print(county, ' random:')\n",
    "    print(wash2)\n",
    "    lines.append(f'{county} Random:\\n{wash2}')\n",
    "\n",
    "with open('FINAL_PRIVACY_RESULTS.txt', \"a\") as f:\n",
    "    for l in lines:\n",
    "        f.write(l + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
