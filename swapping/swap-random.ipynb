{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "%store -r races\n",
    "%store -r races2\n",
    "\n",
    "#ordered race & nonhispanic/hispanic data based on frequency in general US population -\n",
    "# generated from ../dp/create_all_usdistribution.csv\n",
    "real_order = [124, 116, 118, 123, 115, 117, 125, 51, 59, 111, 32, 102, \n",
    "              108, 42, 62, 37, 99, 44, 103, 48, 26, 96, 31, 106, 95, \n",
    "              45, 105, 38, 41, 107, 119, 97, 33, 43, 30, 94, 13, 79, \n",
    "              15, 83, 80, 27, 29, 12, 88, 76, 11, 78, 4, 17, 81, 75, \n",
    "              19, 74, 14, 6, 67, 68, 1, 10, 65, 5, 64, 63, 0, 66, 69, \n",
    "              71, 70, 2, 73, 8, 7, 84, 3, 72, 91, 77, 85, 20, 82, 21,\n",
    "              24, 9, 18, 28, 104, 22, 110, 87, 25, 86, 89, 92, 35, 90,\n",
    "              40, 36, 100, 50, 47, 16, 93, 39, 23, 98, 34, 56, 114, 57, \n",
    "              101, 113, 54, 46, 52, 49, 60, 55, 120, 53, 58, 109, 112, 61, 122, 121]\n",
    "print(real_order.index(48+63))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################################\n",
    "#This method imports county data from csv file to pandas df and reformats race data numerically\n",
    "############################################################################################################################\n",
    "def import_countydata(county):\n",
    "    #import csv file as dataframe\n",
    "    df = pd.read_csv (r'../homemade_data/'+county+'.csv')\n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "    #transfer race representation to include hispanic data:\n",
    "    #if not hispanic: index is 0-62\n",
    "    #if hispanic: index is 63-126\n",
    "        #so, if hispanic, add 63 to the existing race value\n",
    "    for index, row in df.iterrows():\n",
    "        d = row['race']\n",
    "        h = row['hispanic']\n",
    "        if d in races and h==0:\n",
    "            df.at[index, 'race'] = real_order.index(races.index(d))\n",
    "        elif d in races and h==1:\n",
    "            df.at[index, 'race'] = real_order.index((races.index(d))+63)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################################\n",
    "#This method imports state data from csv file to pandas df and reformats race data numerically\n",
    "#------------------------------\n",
    "#INPUT:\n",
    "    #state: state to import and organize data for\n",
    "#------------------------------\n",
    "#OUTPUT:\n",
    "#final_dfs: list containing occurences of each real_order race index\n",
    "    #ex. final_dfs[race]= rows in state dataset that have the same real order value \n",
    "############################################################################################################################\n",
    "def import_statedata(state):\n",
    "    #import csv file as dataframe\n",
    "    df = pd.read_csv (r'state_data/'+state+'.csv')\n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "   \n",
    "    for index, row in df.iterrows():        \n",
    "    #transfer race representation to include hispanic data:\n",
    "        #if not hispanic: index is 0-62\n",
    "        #if hispanic: index is 63-126\n",
    "            #so, if hispanic, add 63 to the existing race value    \n",
    "        d = row['race']\n",
    "        h = row['hispanic']\n",
    "        if d in races2 and h==0:\n",
    "            df.at[index, 'race'] = real_order.index(races2.index(d))\n",
    "        elif d in races2 and h==1:\n",
    "            df.at[index, 'race'] = real_order.index(races2.index(d)+63)\n",
    "\n",
    "    #returns list of real_orders with corresponding values in dataset  \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################################\n",
    "#GET ROWS PRIORITIZED FOR SWAPPING\n",
    "#Get variables prioritized to be swapped \n",
    "#This method returns rows based upon whether they are unique in the dataset\n",
    "############################################################################################################################\n",
    "\n",
    "def pick_swapvars(df):\n",
    "    #all v is collection of all row values\n",
    "    all_v = []\n",
    "\n",
    "    #add all rows to list all_v\n",
    "    for i, row in df.iterrows():\n",
    "        all_v.append([[row['age'], row['sex'], row['race']], row['id']])\n",
    "        \n",
    "    #drop duplicates based upon age, sex, and race from df\n",
    "    df_drop = df.drop_duplicates(subset = ['age', 'sex', 'race'])\n",
    "        \n",
    "    #the list of ids of all rows that contain unique entries\n",
    "    swap = []\n",
    "    \n",
    "    #for each item in uniques, check how many times it occurs in original data\n",
    "    for i, row in df_drop.iterrows():\n",
    "        #list containing age, sex, race\n",
    "        check = [row['age'], row['sex'], row['race']]\n",
    "        dcount = 0 \n",
    "        #for all rows in the dataframe\n",
    "        for a in all_v:\n",
    "            #check if the age, sex, and races match the row\n",
    "            if a[0]==check:\n",
    "                #if they do match, incremement by 1\n",
    "                dcount +=1\n",
    "        #if only present once, add to swaps\n",
    "        if dcount == 1:\n",
    "            swap.append(row['id']-1)\n",
    "            \n",
    "               \n",
    "    return swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################################\n",
    "#GET ALL ROWS TO SWAP\n",
    "#----------------------------------------------------\n",
    "#INPUT\n",
    "    #dframe: full pandas dataset\n",
    "    #swaprate: % to swap at\n",
    "    #swap: the list of ids of all rows that contain unique entries\n",
    "#----------------------------------------------------\n",
    "#OUTPUT\n",
    "    #returns list of rows to swap, list of rows to not swap, & # of rows to b swapped\n",
    "############################################################################################################################\n",
    "\n",
    "def get_rows_to_swap(dframe, swaprate, swap):\n",
    "    \n",
    "    #number of rows we need to swap in the dataset, based upon the given swap rate \n",
    "    rows_to_swap = swaprate*dframe.shape[0]\n",
    "    rows_to_swap = round(rows_to_swap)\n",
    "    \n",
    "    #rows to be swapped and not swapped\n",
    "    swaps = []\n",
    "    not_swaps = []\n",
    "    \n",
    "    #if more rows need to be swapped than there are unique rows present in swap\n",
    "    if rows_to_swap > len(swap):\n",
    "        #add all unique rows to swaps\n",
    "        swaps = swap\n",
    "        #all rows in dataset to choose from to supplementally swap\n",
    "        rows = np.arange(0,dframe.shape[0], 1)        \n",
    "        #find one not already in swaps and add it to swaps\n",
    "        while len(swaps) < rows_to_swap:\n",
    "            random_s = random.choice(rows)\n",
    "            if random_s not in swaps:\n",
    "                swaps.append(random_s)\n",
    "\n",
    "    # else if number of rows needed to be swapped is less than or equal to unique rows present in swap\n",
    "    else:\n",
    "        #all unique rows in dataset to choose from to swap\n",
    "        rows2 = np.arange(0,len(swap), 1)\n",
    "        #find one not already in swaps and add it to swaps \n",
    "        while len(swaps) < rows_to_swap:\n",
    "            random_s = swap[random.choice(rows2)]\n",
    "            if random_s not in swaps:\n",
    "                swaps.append(random_s)\n",
    "\n",
    "    #if not present in swaps, add to not_swaps \n",
    "    for i in range(0,dframe.shape[0]):\n",
    "        if i not in swaps:\n",
    "            not_swaps.append(i)\n",
    "\n",
    "    #returns list of rows to swap, list of rows to not swap, & # of rows to b swapped\n",
    "    return swaps, not_swaps, rows_to_swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################################\n",
    "#FIND THE SWAP\n",
    "#INPUT \n",
    "#dframe = dataset containing r \n",
    "#r = row to swap\n",
    "#thresholds for each variable type\n",
    "#------------------\n",
    "#OUTPUT\n",
    "#return row to be swapped, and the thresholds at which this match was made\n",
    "############################################################################################################################\n",
    "\n",
    "def find_swap(dframe, r, df_state):\n",
    "    \n",
    "    #find similar row in state dataframe\n",
    "    age = dframe.at[r, 'age']\n",
    "    sex = dframe.at[r, 'sex']\n",
    "    \n",
    "    threshold_age = 0\n",
    "    \n",
    "    complete = False\n",
    "    while complete == False:\n",
    "        #filter for age\n",
    "        new_data = df_state[df_state['age']>= int(age-threshold_age)]       \n",
    "        new_data = new_data[new_data['age']<=int(age+threshold_age)]      \n",
    "        #sex\n",
    "        new_data = new_data[new_data['sex']==sex]\n",
    "\n",
    "        #check if done (if there are any matches)\n",
    "        if new_data.shape[0] > 0:\n",
    "            final = new_data.sample()\n",
    "            complete = True\n",
    "            break\n",
    "            \n",
    "        else:\n",
    "            threshold_age +=2\n",
    "    print(threshold_age)\n",
    "            \n",
    "\n",
    "    #return row to be swapped, and the thresholds at which this match was made\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################################\n",
    "#DO THE SWAP\n",
    "#INPUT \n",
    "#final = row in state dataset to swap\n",
    "#r = row in block dataset to swap\n",
    "#df_county = county dataset\n",
    "#------------------\n",
    "#OUTPUT\n",
    "#dframe: new county dataset\n",
    "############################################################################################################################\n",
    "\n",
    "def do_swap(dframe, r, final):\n",
    "\n",
    "    #set new values\n",
    "    dframe.at[r, 'age'] = final['age']\n",
    "    dframe.at[r, 'sex'] = final['sex'].values[0]\n",
    "    dframe.at[r, 'hispanic'] = final['hispanic']\n",
    "    dframe.at[r, 'race'] = final['race'].values[0]\n",
    "    dframe.at[r, 'SwapVal'] = True        \n",
    "    dframe.at[r, 'household_size'] = final['household_size']\n",
    "    dframe.at[r, 'household_tenure'] = final['household_tenure'].values[0]\n",
    "    \n",
    "    return dframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################################\n",
    "#SWAPPING IMPLEMENTATION - SIMILARITY BASED --> given a county block dataset and state dataset, swaps at a given \n",
    "                                                #swaprate and threshold    \n",
    "#INPUT:\n",
    "#dfr = county block dataset \n",
    "#swaprate = rate of data to swap out from county block\n",
    "#swap = list of unique entries prioritized for swapping\n",
    "#df_state = state dataset\n",
    "#thresholds: limit to neighboring values we can draw from for similarity\n",
    "#-----------------------------------\n",
    "#OUTPUT: \n",
    "#dframe = new de-identified county block dataset\n",
    "############################################################################################################################\n",
    "def swap(dfr, swaprate, swap, df_state):\n",
    "    \n",
    "    #num_of_swaps: number of swaps remaining to do\n",
    "    num_of_swaps = 0\n",
    "    #import dataframe, set all rows to swapval of false\n",
    "    dframe = dfr.copy()\n",
    "    dframe['SwapVal'] = 'False'\n",
    "    \n",
    "    print(dframe)\n",
    "    #get rows to swap, rows to not swap, and number of rows to be swapped\n",
    "    swaps, not_swaps, rows_to_swap = get_rows_to_swap(dframe, swaprate, swap)\n",
    "\n",
    "    #while still swaps available to make\n",
    "    while num_of_swaps < rows_to_swap:\n",
    "        \n",
    "        #choose a row from swaps to swap, and then remove from swap list\n",
    "        rows = np.arange(0,len(swaps), 1)\n",
    "        r = swaps[random.choice(rows)]\n",
    "        swaps.remove(r)\n",
    "    \n",
    "        #get row from state distribution to swap with r, and thresholds that returned this val\n",
    "        final = find_swap(dframe, r, df_state)\n",
    "        #swap row from state distribution with r\n",
    "        dframe = do_swap(dframe, r, final)\n",
    "\n",
    "        #increment swap count\n",
    "        num_of_swaps = num_of_swaps +1\n",
    "     \n",
    "    #reset race to their original values \n",
    "    for index, row in dframe.iterrows():\n",
    "        #change from real_order indexes to actual race values\n",
    "        dframe.at[index, 'race'] = real_order[row['race']]\n",
    "        #if hispanic, reset race values to 0-63\n",
    "        if dframe.at[index, 'race'] >62:\n",
    "            dframe.at[index, 'race'] = int(dframe.at[index, 'race'])-63\n",
    "\n",
    "    \n",
    "    return dframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################### RUNNING THE CODE #####################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING\n",
    "\n",
    "# state = 'test_state'\n",
    "# county = 'test_county'\n",
    "\n",
    "# df = import_countydata(county)\n",
    "# df_state = import_statedata(state)\n",
    "\n",
    "# swaprates = [.1]\n",
    "\n",
    "# threshold_age = 5\n",
    "# threshold_sex = 1\n",
    "# threshold_race = 3\n",
    "\n",
    "# for s in swaprates:\n",
    "#     print(s)\n",
    "#     s = float(s)\n",
    "#     swapped = pick_swapvars(df)           \n",
    "#     dframe = swap(df, s, swapped, df_state)\n",
    "#     print(dframe)\n",
    "#     k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "armstrong pennsylvania\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-188-ccf353d423c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimport_countydata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mdf_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimport_statedata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m<\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mswaprates\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-177-3629f95e7682>\u001b[0m in \u001b[0;36mimport_statedata\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m~\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'^Unnamed'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;31m#transfer race representation to include hispanic data:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m#if not hispanic: index is 0-62\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36miterrows\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    950\u001b[0m         \u001b[0mklass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    953\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    303\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m             \u001b[0minferred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfer_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    500\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0minferred\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"interval\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"period\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m                 \u001b[0msubarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.infer_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib._try_infer_map\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_dtype.py\u001b[0m in \u001b[0;36m_name_get\u001b[1;34m(dtype)\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m         \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_kind_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m     \u001b[1;31m# append bit counts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_dtype.py\u001b[0m in \u001b[0;36m_kind_name\u001b[1;34m(dtype)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_kind_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_kind_to_stem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         raise RuntimeError(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "states = [\"pennsylvania\", \"newmexico\", \"georgia\", \"northdakota\", \"hawaii\", \"missouri\", \"massachussets\", \"vermont\"]\n",
    "counties = ['armstrong', 'cibola', 'fayette', 'grandforks', 'hawaii', 'jefferson', 'nantucket', 'washington']\n",
    "\n",
    "swaprates = np.arange(.01, 1.0, .2, float)\n",
    "k=0\n",
    "\n",
    "threshold_age = 5\n",
    "threshold_sex = 1\n",
    "threshold_race = 3\n",
    "\n",
    "\n",
    "for i in range(0,len(states)):\n",
    "    county = counties[i]\n",
    "    state = states[i]\n",
    "    print(county, state)\n",
    "    df = import_countydata(county)\n",
    "    df_state = import_statedata(state)\n",
    "    while k <1:\n",
    "        for s in swaprates:\n",
    "            print(s)\n",
    "            s = float(s)\n",
    "            swapped = pick_swapvars(df)           \n",
    "            dframe = swap(df, s, swapped, df_state) \n",
    "            filename = \"swap_runs/\"+county+\"/random/swap_\"+str(s)+\"_\"+str(k)+\".csv\"\n",
    "            csv_orig_data = dframe.to_csv(filename, index = True)\n",
    "        k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
