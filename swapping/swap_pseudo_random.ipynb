{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import Counter\n",
    "import sys\n",
    "\n",
    "races = ['Total!!Population of one race!!White alone',\n",
    "       'Total!!Population of one race!!Black or African American alone',\n",
    "       'Total!!Population of one race!!American Indian and Alaska Native alone',\n",
    "       'Total!!Population of one race!!Asian alone',\n",
    "       'Total!!Population of one race!!Native Hawaiian and Other Pacific Islander alone',\n",
    "       'Total!!Population of one race!!Some Other Race alone',\n",
    "       'Total!!Two or More Races!!Population of two races!!White; Black or African American',\n",
    "       'Total!!Two or More Races!!Population of two races!!White; American Indian and Alaska Native',\n",
    "       'Total!!Two or More Races!!Population of two races!!White; Asian',\n",
    "       'Total!!Two or More Races!!Population of two races!!White; Native Hawaiian and Other Pacific Islander',\n",
    "       'Total!!Two or More Races!!Population of two races!!White; Some Other Race',\n",
    "       'Total!!Two or More Races!!Population of two races!!Black or African American; American Indian and Alaska Native',\n",
    "       'Total!!Two or More Races!!Population of two races!!Black or African American; Asian',\n",
    "       'Total!!Two or More Races!!Population of two races!!Black or African American; Native Hawaiian and Other Pacific Islander',\n",
    "       'Total!!Two or More Races!!Population of two races!!Black or African American; Some Other Race',\n",
    "       'Total!!Two or More Races!!Population of two races!!American Indian and Alaska Native; Asian',\n",
    "       'Total!!Two or More Races!!Population of two races!!American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
    "       'Total!!Two or More Races!!Population of two races!!American Indian and Alaska Native; Some Other Race',\n",
    "       'Total!!Two or More Races!!Population of two races!!Asian; Native Hawaiian and Other Pacific Islander',\n",
    "       'Total!!Two or More Races!!Population of two races!!Asian; Some Other Race',\n",
    "       'Total!!Two or More Races!!Population of two races!!Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'Total!!Two or More Races!!Population of three races!!White; Black or African American; American Indian and Alaska Native',\n",
    "       'Total!!Two or More Races!!Population of three races!!White; Black or African American; Asian',\n",
    "       'Total!!Two or More Races!!Population of three races!!White; Black or African American; Native Hawaiian and Other Pacific Islander',\n",
    "       'Total!!Two or More Races!!Population of three races!!White; Black or African American; Some Other Race',\n",
    "       'Total!!Two or More Races!!Population of three races!!White; American Indian and Alaska Native; Asian',\n",
    "       'Total!!Two or More Races!!Population of three races!!White; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
    "       'Total!!Two or More Races!!Population of three races!!White; American Indian and Alaska Native; Some Other Race',\n",
    "       'Total!!Two or More Races!!Population of three races!!White; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "       'Total!!Two or More Races!!Population of three races!!White; Asian; Some Other Race',\n",
    "       'Total!!Two or More Races!!Population of three races!!White; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'Total!!Two or More Races!!Population of three races!!Black or African American; American Indian and Alaska Native; Asian',\n",
    "       'Total!!Two or More Races!!Population of three races!!Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
    "       'Total!!Two or More Races!!Population of three races!!Black or African American; American Indian and Alaska Native; Some Other Race',\n",
    "       'Total!!Two or More Races!!Population of three races!!Black or African American; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "       'Total!!Two or More Races!!Population of three races!!Black or African American; Asian; Some Other Race',\n",
    "       'Total!!Two or More Races!!Population of three races!!Black or African American; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'Total!!Two or More Races!!Population of three races!!American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "       'Total!!Two or More Races!!Population of three races!!American Indian and Alaska Native; Asian; Some Other Race',\n",
    "       'Total!!Two or More Races!!Population of three races!!American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'Total!!Two or More Races!!Population of three races!!Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'Total!!Two or More Races!!Population of four races!!White; Black or African American; American Indian and Alaska Native; Asian',\n",
    "       'Total!!Two or More Races!!Population of four races!!White; Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
    "       'Total!!Two or More Races!!Population of four races!!White; Black or African American; American Indian and Alaska Native; Some Other Race',\n",
    "       'Total!!Two or More Races!!Population of four races!!White; Black or African American; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "       'Total!!Two or More Races!!Population of four races!!White; Black or African American; Asian; Some Other Race',\n",
    "       'Total!!Two or More Races!!Population of four races!!White; Black or African American; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'Total!!Two or More Races!!Population of four races!!White; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "       'Total!!Two or More Races!!Population of four races!!White; American Indian and Alaska Native; Asian; Some Other Race',\n",
    "       'Total!!Two or More Races!!Population of four races!!White; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'Total!!Two or More Races!!Population of four races!!White; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'Total!!Two or More Races!!Population of four races!!Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "       'Total!!Two or More Races!!Population of four races!!Black or African American; American Indian and Alaska Native; Asian; Some Other Race',\n",
    "       'Total!!Two or More Races!!Population of four races!!Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'Total!!Two or More Races!!Population of four races!!Black or African American; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'Total!!Two or More Races!!Population of four races!!American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'Total!!Two or More Races!!Population of five races!!White; Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "       'Total!!Two or More Races!!Population of five races!!White; Black or African American; American Indian and Alaska Native; Asian; Some Other Race',\n",
    "       'Total!!Two or More Races!!Population of five races!!White; Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'Total!!Two or More Races!!Population of five races!!White; Black or African American; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'Total!!Two or More Races!!Population of five races!!White; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'Total!!Two or More Races!!Population of five races!!Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'Total!!Two or More Races!!Population of six races!!White; Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race']\n",
    "\n",
    "\n",
    "races2 = ['White alone',\n",
    "       'Black or African American alone',\n",
    "       'American Indian and Alaska Native alone',\n",
    "       'Asian alone',\n",
    "       'Native Hawaiian and Other Pacific Islander alone',\n",
    "       'Some Other Race alone',\n",
    "       'White; Black or African American',\n",
    "       'White; American Indian and Alaska Native',\n",
    "       'White; Asian',\n",
    "       'White; Native Hawaiian and Other Pacific Islander',\n",
    "       'White; Some Other Race',\n",
    "       'Black or African American; American Indian and Alaska Native',\n",
    "       'Black or African American; Asian',\n",
    "       'Black or African American; Native Hawaiian and Other Pacific Islander',\n",
    "       'Black or African American; Some Other Race',\n",
    "       'American Indian and Alaska Native; Asian',\n",
    "       'American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
    "       'American Indian and Alaska Native; Some Other Race',\n",
    "       'Asian; Native Hawaiian and Other Pacific Islander',\n",
    "       'Asian; Some Other Race',\n",
    "       'Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'White; Black or African American; American Indian and Alaska Native',\n",
    "       'White; Black or African American; Asian',\n",
    "       'White; Black or African American; Native Hawaiian and Other Pacific Islander',\n",
    "       'White; Black or African American; Some Other Race',\n",
    "       'White; American Indian and Alaska Native; Asian',\n",
    "       'White; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
    "       'White; American Indian and Alaska Native; Some Other Race',\n",
    "       'White; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "       'White; Asian; Some Other Race',\n",
    "       'White; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'Black or African American; American Indian and Alaska Native; Asian',\n",
    "       'Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
    "       'Black or African American; American Indian and Alaska Native; Some Other Race',\n",
    "       'Black or African American; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "       'Black or African American; Asian; Some Other Race',\n",
    "       'Black or African American; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "       'American Indian and Alaska Native; Asian; Some Other Race',\n",
    "       'American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'White; Black or African American; American Indian and Alaska Native; Asian',\n",
    "       'White; Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
    "       'White; Black or African American; American Indian and Alaska Native; Some Other Race',\n",
    "       'White; Black or African American; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "       'White; Black or African American; Asian; Some Other Race',\n",
    "       'White; Black or African American; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'White; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "       'White; American Indian and Alaska Native; Asian; Some Other Race',\n",
    "       'White; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'White; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "       'Black or African American; American Indian and Alaska Native; Asian; Some Other Race',\n",
    "       'Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'Black or African American; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'White; Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "       'White; Black or African American; American Indian and Alaska Native; Asian; Some Other Race',\n",
    "       'White; Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'White; Black or African American; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'White; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'White; Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race']\n",
    "\n",
    "\n",
    "#ordered race & nonhispanic/hispanic data based on frequency in general US population -\n",
    "# generated from ../dp/create_all_usdistribution.csv\n",
    "real_order = [124, 116, 118, 123, 115, 117, 125, 51, 59, 111, 32, 102, \n",
    "              108, 42, 62, 37, 99, 44, 103, 48, 26, 96, 31, 106, 95, \n",
    "              45, 105, 38, 41, 107, 119, 97, 33, 43, 30, 94, 13, 79, \n",
    "              15, 83, 80, 27, 29, 12, 88, 76, 11, 78, 4, 17, 81, 75, \n",
    "              19, 74, 14, 6, 67, 68, 1, 10, 65, 5, 64, 63, 0, 66, 69, \n",
    "              71, 70, 2, 73, 8, 7, 84, 3, 72, 91, 77, 85, 20, 82, 21,\n",
    "              24, 9, 18, 28, 104, 22, 110, 87, 25, 86, 89, 92, 35, 90,\n",
    "              40, 36, 100, 50, 47, 16, 93, 39, 23, 98, 34, 56, 114, 57, \n",
    "              101, 113, 54, 46, 52, 49, 60, 55, 120, 53, 58, 109, 112, 61, 122, 121]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################################\n",
    "#This method imports county data from csv file to pandas df and reformats race data numerically\n",
    "############################################################################################################################\n",
    "def import_countydata(county):\n",
    "    #import csv file as dataframe\n",
    "    df = pd.read_csv (r'../homemade_data/'+county+'.csv')\n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "    #transfer race representation to include hispanic data:\n",
    "    #if not hispanic: index is 0-62\n",
    "    #if hispanic: index is 63-126\n",
    "        #so, if hispanic, add 63 to the existing race value\n",
    "    for index, row in df.iterrows():\n",
    "        d = row['race']\n",
    "        h = row['hispanic']\n",
    "        if d in races and h==0:\n",
    "            df.at[index, 'race'] = real_order.index(races.index(d))\n",
    "        elif d in races and h==1:\n",
    "            df.at[index, 'race'] = real_order.index((races.index(d))+63)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################################\n",
    "#This method imports state data from csv file to pandas df and reformats race data numerically\n",
    "#------------------------------\n",
    "#INPUT:\n",
    "    #state: state to import and organize data for\n",
    "#------------------------------\n",
    "#OUTPUT:\n",
    "#final_dfs: list containing occurences of each real_order race index\n",
    "    #ex. final_dfs[race]= rows in state dataset that have the same real order value \n",
    "############################################################################################################################\n",
    "def import_statedata(state):\n",
    "    #import csv file as dataframe\n",
    "    df = pd.read_csv (r'state_data/'+state+'.csv')\n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "   \n",
    "    for index, row in df.iterrows():        \n",
    "    #transfer race representation to include hispanic data:\n",
    "        #if not hispanic: index is 0-62\n",
    "        #if hispanic: index is 63-126\n",
    "            #so, if hispanic, add 63 to the existing race value    \n",
    "        d = row['race']\n",
    "        h = row['hispanic']\n",
    "        if d in races2 and h==0:\n",
    "            df.at[index, 'race'] = real_order.index(races2.index(d))\n",
    "        elif d in races2 and h==1:\n",
    "            df.at[index, 'race'] = real_order.index(races2.index(d)+63)\n",
    "\n",
    "    #returns list of real_orders with corresponding values in dataset  \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################################\n",
    "#GET ROWS PRIORITIZED FOR SWAPPING\n",
    "#Get variables prioritized to be swapped \n",
    "#This method returns rows based upon whether they are unique in the dataset\n",
    "############################################################################################################################\n",
    "\n",
    "def pick_swapvars(df):\n",
    "    #all v is collection of all row values\n",
    "    all_v = []\n",
    "\n",
    "    #add all rows to list all_v\n",
    "    for i, row in df.iterrows():\n",
    "        all_v.append([[row['age'], row['sex'], row['race']], row['id']])\n",
    "        \n",
    "    #drop duplicates based upon age, sex, and race from df\n",
    "    df_drop = df.drop_duplicates(subset = ['age', 'sex', 'race'])\n",
    "        \n",
    "    #the list of ids of all rows that contain unique entries\n",
    "    swap = []\n",
    "    \n",
    "    #for each item in uniques, check how many times it occurs in original data\n",
    "    for i, row in df_drop.iterrows():\n",
    "        #list containing age, sex, race\n",
    "        check = [row['age'], row['sex'], row['race']]\n",
    "        dcount = 0 \n",
    "        #for all rows in the dataframe\n",
    "        for a in all_v:\n",
    "            #check if the age, sex, and races match the row\n",
    "            if a[0]==check:\n",
    "                #if they do match, incremement by 1\n",
    "                dcount +=1\n",
    "        #if only present once, add to swaps\n",
    "        if dcount == 1:\n",
    "            swap.append(row['id']-1)\n",
    "            \n",
    "               \n",
    "    return swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################################\n",
    "#GET ALL ROWS TO SWAP\n",
    "#----------------------------------------------------\n",
    "#INPUT\n",
    "    #dframe: full pandas dataset\n",
    "    #swaprate: % to swap at\n",
    "    #swap: the list of ids of all rows that contain unique entries\n",
    "#----------------------------------------------------\n",
    "#OUTPUT\n",
    "    #returns list of rows to swap, list of rows to not swap, & # of rows to b swapped\n",
    "############################################################################################################################\n",
    "\n",
    "def get_rows_to_swap(dframe, swaprate, swap):\n",
    "    \n",
    "    #number of rows we need to swap in the dataset, based upon the given swap rate \n",
    "    rows_to_swap = swaprate*dframe.shape[0]\n",
    "    rows_to_swap = round(rows_to_swap)\n",
    "    \n",
    "    #rows to be swapped and not swapped\n",
    "    swaps = []\n",
    "    not_swaps = []\n",
    "    \n",
    "    #if more rows need to be swapped than there are unique rows present in swap\n",
    "    if rows_to_swap > len(swap):\n",
    "        #add all unique rows to swaps\n",
    "        swaps = swap\n",
    "        #all rows in dataset to choose from to supplementally swap\n",
    "        rows = np.arange(0,dframe.shape[0], 1)        \n",
    "        #find one not already in swaps and add it to swaps\n",
    "        while len(swaps) < rows_to_swap:\n",
    "            random_s = random.choice(rows)\n",
    "            if random_s not in swaps:\n",
    "                swaps.append(random_s)\n",
    "\n",
    "    # else if number of rows needed to be swapped is less than or equal to unique rows present in swap\n",
    "    else:\n",
    "        #all unique rows in dataset to choose from to swap\n",
    "        rows2 = np.arange(0,len(swap), 1)\n",
    "        #find one not already in swaps and add it to swaps \n",
    "        while len(swaps) < rows_to_swap:\n",
    "            random_s = swap[random.choice(rows2)]\n",
    "            if random_s not in swaps:\n",
    "                swaps.append(random_s)\n",
    "\n",
    "    #if not present in swaps, add to not_swaps \n",
    "    for i in range(0,dframe.shape[0]):\n",
    "        if i not in swaps:\n",
    "            not_swaps.append(i)\n",
    "\n",
    "    #returns list of rows to swap, list of rows to not swap, & # of rows to b swapped\n",
    "    return swaps, not_swaps, rows_to_swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################################\n",
    "#FIND THE SWAP\n",
    "#INPUT \n",
    "#dframe = dataset containing r \n",
    "#r = row to swap\n",
    "#thresholds for each variable type\n",
    "#------------------\n",
    "#OUTPUT\n",
    "#return row to be swapped, and the thresholds at which this match was made\n",
    "############################################################################################################################\n",
    "\n",
    "def find_swap(dframe, r, df_state):\n",
    "    \n",
    "    #find similar row in state dataframe\n",
    "    age = dframe.at[r, 'age']\n",
    "    sex = dframe.at[r, 'sex']\n",
    "    \n",
    "    threshold_age = 0\n",
    "    \n",
    "    complete = False\n",
    "    while complete == False:\n",
    "        #filter for age\n",
    "        new_data = df_state[df_state['age']>= int(age-threshold_age)]       \n",
    "        new_data = new_data[new_data['age']<=int(age+threshold_age)]      \n",
    "        #sex\n",
    "        new_data = new_data[new_data['sex']==sex]\n",
    "\n",
    "        #check if done (if there are any matches)\n",
    "        if new_data.shape[0] > 0:\n",
    "            final = new_data.sample()\n",
    "            complete = True\n",
    "            break\n",
    "            \n",
    "        else:\n",
    "            threshold_age +=2\n",
    "    print(threshold_age)\n",
    "            \n",
    "\n",
    "    #return row to be swapped, and the thresholds at which this match was made\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################################\n",
    "#DO THE SWAP\n",
    "#INPUT \n",
    "#final = row in state dataset to swap\n",
    "#r = row in block dataset to swap\n",
    "#df_county = county dataset\n",
    "#------------------\n",
    "#OUTPUT\n",
    "#dframe: new county dataset\n",
    "############################################################################################################################\n",
    "\n",
    "def do_swap(dframe, r, final):\n",
    "\n",
    "    #set new values\n",
    "    dframe.at[r, 'age'] = final['age']\n",
    "    dframe.at[r, 'sex'] = final['sex'].values[0]\n",
    "    dframe.at[r, 'hispanic'] = final['hispanic']\n",
    "    dframe.at[r, 'race'] = final['race'].values[0]\n",
    "    dframe.at[r, 'SwapVal'] = True        \n",
    "    dframe.at[r, 'household_size'] = final['household_size']\n",
    "    dframe.at[r, 'household_tenure'] = final['household_tenure'].values[0]\n",
    "    \n",
    "    return dframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################################\n",
    "#SWAPPING IMPLEMENTATION - SIMILARITY BASED --> given a county block dataset and state dataset, swaps at a given \n",
    "                                                #swaprate and threshold    \n",
    "#INPUT:\n",
    "#dfr = county block dataset \n",
    "#swaprate = rate of data to swap out from county block\n",
    "#swap = list of unique entries prioritized for swapping\n",
    "#df_state = state dataset\n",
    "#thresholds: limit to neighboring values we can draw from for similarity\n",
    "#-----------------------------------\n",
    "#OUTPUT: \n",
    "#dframe = new de-identified county block dataset\n",
    "############################################################################################################################\n",
    "def swap(dfr, swaprate, swap, df_state):\n",
    "    \n",
    "    #num_of_swaps: number of swaps remaining to do\n",
    "    num_of_swaps = 0\n",
    "    #import dataframe, set all rows to swapval of false\n",
    "    dframe = dfr.copy()\n",
    "    dframe['SwapVal'] = 'False'\n",
    "    \n",
    "    print(dframe)\n",
    "    #get rows to swap, rows to not swap, and number of rows to be swapped\n",
    "    swaps, not_swaps, rows_to_swap = get_rows_to_swap(dframe, swaprate, swap)\n",
    "\n",
    "    #while still swaps available to make\n",
    "    while num_of_swaps < rows_to_swap:\n",
    "        \n",
    "        #choose a row from swaps to swap, and then remove from swap list\n",
    "        rows = np.arange(0,len(swaps), 1)\n",
    "        r = swaps[random.choice(rows)]\n",
    "        swaps.remove(r)\n",
    "    \n",
    "        #get row from state distribution to swap with r, and thresholds that returned this val\n",
    "        final = find_swap(dframe, r, df_state)\n",
    "        #swap row from state distribution with r\n",
    "        dframe = do_swap(dframe, r, final)\n",
    "\n",
    "        #increment swap count\n",
    "        num_of_swaps = num_of_swaps +1\n",
    "     \n",
    "    #reset race to their original values \n",
    "    for index, row in dframe.iterrows():\n",
    "        #change from real_order indexes to actual race values\n",
    "        dframe.at[index, 'race'] = real_order[row['race']]\n",
    "        #if hispanic, reset race values to 0-63\n",
    "        if dframe.at[index, 'race'] >62:\n",
    "            dframe.at[index, 'race'] = int(dframe.at[index, 'race'])-63\n",
    "\n",
    "    \n",
    "    return dframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################### RUNNING THE CODE #####################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN FR\n",
    "\n",
    "def run_code(county, state, k1, k2):\n",
    "\n",
    "    swaprates = np.arange(.01, 1.0, .01, float)\n",
    "\n",
    "    df = import_countydata(county)\n",
    "    df_state = import_statedata(state)\n",
    "    \n",
    "    swapped = pick_swapvars(df)\n",
    "    \n",
    "    while k1 <k2:\n",
    "        \n",
    "        for s in swaprates:\n",
    "            print(s)\n",
    "            s = float(s)\n",
    "            swappers = swapped.copy()        \n",
    "            dframe = swap(df, s, swappers, df_state) \n",
    "            filename = \"swap_runs/\"+county+\"/pseudo_random/swap_\"+str(s)+\"_\"+str(k1)+\".csv\"\n",
    "            csv_orig_data = dframe.to_csv(filename, index = True)\n",
    "            \n",
    "        k1+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMMENT THIS OUT FOR VMS\n",
    "county = 'alameda'\n",
    "state = 'california'\n",
    "k1 = 0\n",
    "k2 = 1\n",
    "\n",
    "\n",
    "#UNCOMMENT THIS FOR VMS\n",
    "# county = int(sys.argv[1])\n",
    "# state = int(sys.argv[2])\n",
    "# k1 = int(sys.argv[3])\n",
    "# k2 = int(sys.argv[4])\n",
    "\n",
    "run_code(county, state, k1, k2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
