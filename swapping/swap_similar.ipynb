{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ordered races&n/hn based on frequency in general US population\n",
    "real_order = [124, 116, 118, 123, 115, 117, 125, 51, 59, 111, 32, 102, \n",
    "              108, 42, 62, 37, 99, 44, 103, 48, 26, 96, 31, 106, 95, \n",
    "              45, 105, 38, 41, 107, 119, 97, 33, 43, 30, 94, 13, 79, \n",
    "              15, 83, 80, 27, 29, 12, 88, 76, 11, 78, 4, 17, 81, 75, \n",
    "              19, 74, 14, 6, 67, 68, 1, 10, 65, 5, 64, 63, 0, 66, 69, \n",
    "              71, 70, 2, 73, 8, 7, 84, 3, 72, 91, 77, 85, 20, 82, 21,\n",
    "              24, 9, 18, 28, 104, 22, 110, 87, 25, 86, 89, 92, 35, 90,\n",
    "              40, 36, 100, 50, 47, 16, 93, 39, 23, 98, 34, 56, 114, 57, \n",
    "              101, 113, 54, 46, 52, 49, 60, 55, 120, 53, 58, 109, 112, 61, 122, 121]\n",
    "\n",
    "#races for state data\n",
    "races = ['White alone',\n",
    "       'Black or African American alone',\n",
    "       'American Indian and Alaska Native alone',\n",
    "       'Asian alone',\n",
    "       'Native Hawaiian and Other Pacific Islander alone',\n",
    "       'Some Other Race alone',\n",
    "       'White; Black or African American',\n",
    "       'White; American Indian and Alaska Native',\n",
    "       'White; Asian',\n",
    "       'White; Native Hawaiian and Other Pacific Islander',\n",
    "       'White; Some Other Race',\n",
    "       'Black or African American; American Indian and Alaska Native',\n",
    "       'Black or African American; Asian',\n",
    "       'Black or African American; Native Hawaiian and Other Pacific Islander',\n",
    "       'Black or African American; Some Other Race',\n",
    "       'American Indian and Alaska Native; Asian',\n",
    "       'American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
    "       'American Indian and Alaska Native; Some Other Race',\n",
    "       'Asian; Native Hawaiian and Other Pacific Islander',\n",
    "       'Asian; Some Other Race',\n",
    "       'Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'White; Black or African American; American Indian and Alaska Native',\n",
    "       'White; Black or African American; Asian',\n",
    "       'White; Black or African American; Native Hawaiian and Other Pacific Islander',\n",
    "       'White; Black or African American; Some Other Race',\n",
    "       'White; American Indian and Alaska Native; Asian',\n",
    "       'White; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
    "       'White; American Indian and Alaska Native; Some Other Race',\n",
    "       'White; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "       'White; Asian; Some Other Race',\n",
    "       'White; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'Black or African American; American Indian and Alaska Native; Asian',\n",
    "       'Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
    "       'Black or African American; American Indian and Alaska Native; Some Other Race',\n",
    "       'Black or African American; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "       'Black or African American; Asian; Some Other Race',\n",
    "       'Black or African American; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "       'American Indian and Alaska Native; Asian; Some Other Race',\n",
    "       'American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'White; Black or African American; American Indian and Alaska Native; Asian',\n",
    "       'White; Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
    "       'White; Black or African American; American Indian and Alaska Native; Some Other Race',\n",
    "       'White; Black or African American; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "       'White; Black or African American; Asian; Some Other Race',\n",
    "       'White; Black or African American; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'White; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "       'White; American Indian and Alaska Native; Asian; Some Other Race',\n",
    "       'White; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'White; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "       'Black or African American; American Indian and Alaska Native; Asian; Some Other Race',\n",
    "       'Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'Black or African American; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'White; Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "       'White; Black or African American; American Indian and Alaska Native; Asian; Some Other Race',\n",
    "       'White; Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'White; Black or African American; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'White; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "       'White; Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race']\n",
    "    \n",
    "    \n",
    "races2 = ['Total!!Population of one race!!White alone',\n",
    "           'Total!!Population of one race!!Black or African American alone',\n",
    "           'Total!!Population of one race!!American Indian and Alaska Native alone',\n",
    "           'Total!!Population of one race!!Asian alone',\n",
    "           'Total!!Population of one race!!Native Hawaiian and Other Pacific Islander alone',\n",
    "           'Total!!Population of one race!!Some Other Race alone',\n",
    "           'Total!!Two or More Races!!Population of two races!!White; Black or African American',\n",
    "           'Total!!Two or More Races!!Population of two races!!White; American Indian and Alaska Native',\n",
    "           'Total!!Two or More Races!!Population of two races!!White; Asian',\n",
    "           'Total!!Two or More Races!!Population of two races!!White; Native Hawaiian and Other Pacific Islander',\n",
    "           'Total!!Two or More Races!!Population of two races!!White; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of two races!!Black or African American; American Indian and Alaska Native',\n",
    "           'Total!!Two or More Races!!Population of two races!!Black or African American; Asian',\n",
    "           'Total!!Two or More Races!!Population of two races!!Black or African American; Native Hawaiian and Other Pacific Islander',\n",
    "           'Total!!Two or More Races!!Population of two races!!Black or African American; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of two races!!American Indian and Alaska Native; Asian',\n",
    "           'Total!!Two or More Races!!Population of two races!!American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
    "           'Total!!Two or More Races!!Population of two races!!American Indian and Alaska Native; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of two races!!Asian; Native Hawaiian and Other Pacific Islander',\n",
    "           'Total!!Two or More Races!!Population of two races!!Asian; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of two races!!Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of three races!!White; Black or African American; American Indian and Alaska Native',\n",
    "           'Total!!Two or More Races!!Population of three races!!White; Black or African American; Asian',\n",
    "           'Total!!Two or More Races!!Population of three races!!White; Black or African American; Native Hawaiian and Other Pacific Islander',\n",
    "           'Total!!Two or More Races!!Population of three races!!White; Black or African American; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of three races!!White; American Indian and Alaska Native; Asian',\n",
    "           'Total!!Two or More Races!!Population of three races!!White; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
    "           'Total!!Two or More Races!!Population of three races!!White; American Indian and Alaska Native; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of three races!!White; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "           'Total!!Two or More Races!!Population of three races!!White; Asian; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of three races!!White; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of three races!!Black or African American; American Indian and Alaska Native; Asian',\n",
    "           'Total!!Two or More Races!!Population of three races!!Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
    "           'Total!!Two or More Races!!Population of three races!!Black or African American; American Indian and Alaska Native; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of three races!!Black or African American; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "           'Total!!Two or More Races!!Population of three races!!Black or African American; Asian; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of three races!!Black or African American; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of three races!!American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "           'Total!!Two or More Races!!Population of three races!!American Indian and Alaska Native; Asian; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of three races!!American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of three races!!Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of four races!!White; Black or African American; American Indian and Alaska Native; Asian',\n",
    "           'Total!!Two or More Races!!Population of four races!!White; Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander',\n",
    "           'Total!!Two or More Races!!Population of four races!!White; Black or African American; American Indian and Alaska Native; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of four races!!White; Black or African American; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "           'Total!!Two or More Races!!Population of four races!!White; Black or African American; Asian; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of four races!!White; Black or African American; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of four races!!White; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "           'Total!!Two or More Races!!Population of four races!!White; American Indian and Alaska Native; Asian; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of four races!!White; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of four races!!White; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of four races!!Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "           'Total!!Two or More Races!!Population of four races!!Black or African American; American Indian and Alaska Native; Asian; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of four races!!Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of four races!!Black or African American; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of four races!!American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of five races!!White; Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander',\n",
    "           'Total!!Two or More Races!!Population of five races!!White; Black or African American; American Indian and Alaska Native; Asian; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of five races!!White; Black or African American; American Indian and Alaska Native; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of five races!!White; Black or African American; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of five races!!White; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of five races!!Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race',\n",
    "           'Total!!Two or More Races!!Population of six races!!White; Black or African American; American Indian and Alaska Native; Asian; Native Hawaiian and Other Pacific Islander; Some Other Race']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################################\n",
    "#import county data\n",
    "############################################################################################################################\n",
    "def import_countydata(county):\n",
    "    df = pd.read_csv (r'../homemade_data/'+county+'.csv')\n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        d = row['race']\n",
    "        h = row['hispanic']\n",
    "        if d in races2 and h==1:\n",
    "            df.at[index, 'race'] = real_order.index(races2.index(d))\n",
    "        elif d in races2 and h==0:\n",
    "            df.at[index, 'race'] = real_order.index((races2.index(d))+63)\n",
    "        \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################################\n",
    "#import state data\n",
    "############################################################################################################################\n",
    "def import_statedata(state):\n",
    "    df = pd.read_csv (r'state_data/'+state+'.csv')\n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if index%100000 == 0:\n",
    "            print(index)\n",
    "        d = row['race']\n",
    "        h = row['hispanic']\n",
    "        if d in races and h==1:\n",
    "            df.at[index, 'race'] = real_order.index(races.index(d))\n",
    "        elif d in races and h==0:\n",
    "            df.at[index, 'race'] = real_order.index(races.index(d)+63)\n",
    "                            \n",
    "    final_dfs = {}\n",
    "\n",
    "    for race in range(0,126):\n",
    "        final_dfs[race] = (df[df['race'] == race]).sort_values(by='age')\n",
    "\n",
    "    return final_dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################################\n",
    "#sample w/out replacement\n",
    "#https://codegolf.stackexchange.com/questions/4772/random-sampling-without-replacement\n",
    "############################################################################################################################\n",
    "\n",
    "def rand_sample(n, lower, upper):\n",
    "    result = []\n",
    "    pool = {}\n",
    "    for _ in range(n):\n",
    "        i = random.randint(lower, upper)\n",
    "        x = pool.get(i, i)\n",
    "        pool[i] = pool.get(lower, lower)\n",
    "        lower += 1\n",
    "        result.append(x)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################################\n",
    "#select variables to be swapped \n",
    "#this implementation selects them based upon whether they are unique\n",
    "############################################################################################################################\n",
    "\n",
    "def pick_swapvars(df):\n",
    "    all_v = []\n",
    "    swap = []\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        all_v.append([[row['age'], row['sex'], row['race']], row['id']])\n",
    "    df_drop = df.drop_duplicates(subset = ['age', 'sex', 'race'])\n",
    "    for i, row in df_drop.iterrows():\n",
    "        check = [row['age'], row['sex'], row['race']]\n",
    "        dcount = 0 \n",
    "        for a in all_v:\n",
    "            if a[0]==check:\n",
    "                dcount +=1\n",
    "        if dcount == 1:\n",
    "            swap.append(row['id']-1)\n",
    "    return swap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################################\n",
    "#SWAP FUNCTION\n",
    "############################################################################################################################\n",
    "def swap_rows():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################################\n",
    "#SWAPPING IMPLEMENTATION - SIMILARITY BASED\n",
    "############################################################################################################################\n",
    "def swap(dfr, swaprate, swap, df_state):\n",
    "    rs = 0 #num of swaps\n",
    "    false_swaps = 0\n",
    "    final_swaps = []\n",
    "    all_good = 0\n",
    "    dframe = dfr.copy()\n",
    "    dframe['SwapVal'] = 'False'\n",
    "    \n",
    "    #number of vars to swap\n",
    "    rts = swaprate*dframe.shape[0]\n",
    "    rts = round(rts)\n",
    "    if rts >= len(swap)-1:\n",
    "        swaps = swap\n",
    "        swappos = np.arange(0,dframe.shape[0]-1, 1)\n",
    "        while len(swaps) < rts:\n",
    "            random_s = random.choice(swappos)\n",
    "            if random_s not in swaps:\n",
    "                swaps.append(random_s)\n",
    "\n",
    "    else:\n",
    "        #swappos is random selection of indexes of swap \n",
    "        swappos = rand_sample(rts, 0, len(swap)-1)\n",
    "        swaps = []\n",
    "        idx = 0\n",
    "        for swapval in swap:\n",
    "            if idx in swappos:\n",
    "                swaps.append(swapval)\n",
    "            idx +=1   \n",
    "\n",
    "    not_swaps = []\n",
    "    for i in range(0,dframe.shape[0]):\n",
    "        if i not in swaps:\n",
    "            not_swaps.append(i)\n",
    "\n",
    "    rts = len(swaps)\n",
    "    \n",
    "#     while still swaps available to make\n",
    "    while rs<rts:\n",
    "        r1 = rand_sample(1, 0, len(swaps)-1)\n",
    "        r1 = swaps[r1[0]]\n",
    "        swaps.remove(r1)\n",
    "        \n",
    "        #find similar in california (df_cali)\n",
    "        age = dframe.at[r1, 'age']\n",
    "        sex = dframe.at[r1, 'sex']\n",
    "        race = dframe.at[r1, 'race']\n",
    "        \n",
    "        #CHANGE THESE HERE\n",
    "        complete = False\n",
    "        threshold_age = 5\n",
    "        threshold_sex = 1\n",
    "        threshold_race = 3\n",
    "        \n",
    "    \n",
    "        #find someone similar in state\n",
    "        done = False \n",
    "        while complete == False:\n",
    "            \n",
    "            #race\n",
    "            new_data = df_state[real_order.index(race)]    \n",
    "            i=1\n",
    "            \n",
    "            while i <=threshold_race:\n",
    "                if(race-i >= 0):\n",
    "                    new_data = new_data.append(df_state[race-i], ignore_index=True)\n",
    "                if(race+i <= 125):\n",
    "                    new_data = new_data.append(df_state[race+i], ignore_index=True)\n",
    "                i+=1\n",
    "\n",
    "            #age\n",
    "            new_data = new_data[new_data['age']>= int(age-threshold_age)]       \n",
    "            new_data = new_data[new_data['age']<=int(age+threshold_age)]\n",
    "\n",
    "            #sex\n",
    "            if threshold_sex == 0:\n",
    "                new_data = new_data[new_data['sex']==sex]\n",
    "\n",
    "            #check if done\n",
    "            if new_data.shape[0] > 0:\n",
    "                final = new_data.sample()\n",
    "                done = True\n",
    "                ra = df_state[race]\n",
    "                df_state[race] = ra\n",
    "                complete = True\n",
    "                break\n",
    "                \n",
    "            #else increment thresholds and try again\n",
    "            else: \n",
    "                threshold_race = threshold_race + 2\n",
    "                threshold_age = threshold_age + 2\n",
    "                \n",
    "        \n",
    "        rrr = real_order[int(final['race'])]\n",
    "        if rrr>62:\n",
    "            rrr = rrr-63\n",
    "        \n",
    "        #set new values\n",
    "        dframe.at[r1, 'age'] = final['age']\n",
    "        dframe.at[r1, 'sex'] = final['sex'].values[0]\n",
    "        dframe.at[r1, 'hispanic'] = final['hispanic']\n",
    "        dframe.at[r1, 'race'] = rrr\n",
    "        dframe.at[r1, 'SwapVal'] = True        \n",
    "        dframe.at[r1, 'household_size'] = final['household_size']\n",
    "        dframe.at[r1, 'household_tenure'] = final['household_tenure'].values[0]\n",
    "\n",
    "        rs = rs +1\n",
    "        \n",
    "        \n",
    "    for index, row in dframe.iterrows():\n",
    "        if row['SwapVal'] == 'False' :\n",
    "            dframe.at[index, 'race'] = real_order[row['race']]\n",
    "            if row['hispanic']==0:\n",
    "                dframe.at[index, 'race'] = int(real_order[row['race']])-63\n",
    "\n",
    "    return dframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alameda california\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "0.01\n",
      "0.060000000000000005\n",
      "0.11\n",
      "0.16000000000000003\n",
      "0.21000000000000002\n",
      "0.26\n",
      "0.31000000000000005\n",
      "0.36000000000000004\n",
      "0.41000000000000003\n",
      "0.46\n",
      "0.51\n",
      "0.56\n",
      "0.6100000000000001\n",
      "0.66\n",
      "0.7100000000000001\n",
      "0.76\n",
      "0.81\n",
      "0.8600000000000001\n",
      "0.91\n",
      "0.9600000000000001\n",
      "0.01\n",
      "0.060000000000000005\n",
      "0.11\n",
      "0.16000000000000003\n",
      "0.21000000000000002\n",
      "0.26\n",
      "0.31000000000000005\n",
      "0.36000000000000004\n",
      "0.41000000000000003\n",
      "0.46\n",
      "0.51\n",
      "0.56\n",
      "0.6100000000000001\n",
      "0.66\n",
      "0.7100000000000001\n",
      "0.76\n",
      "0.81\n",
      "0.8600000000000001\n",
      "0.91\n",
      "0.9600000000000001\n",
      "0.01\n",
      "0.060000000000000005\n",
      "0.11\n",
      "0.16000000000000003\n",
      "0.21000000000000002\n",
      "0.26\n",
      "0.31000000000000005\n",
      "0.36000000000000004\n",
      "0.41000000000000003\n",
      "0.46\n",
      "0.51\n",
      "0.56\n",
      "0.6100000000000001\n",
      "0.66\n",
      "0.7100000000000001\n",
      "0.76\n",
      "0.81\n",
      "0.8600000000000001\n",
      "0.91\n",
      "0.9600000000000001\n",
      "0.01\n",
      "0.060000000000000005\n",
      "0.11\n",
      "0.16000000000000003\n",
      "0.21000000000000002\n",
      "0.26\n",
      "0.31000000000000005\n",
      "0.36000000000000004\n",
      "0.41000000000000003\n",
      "0.46\n",
      "0.51\n",
      "0.56\n",
      "0.6100000000000001\n",
      "0.66\n",
      "0.7100000000000001\n",
      "0.76\n",
      "0.81\n",
      "0.8600000000000001\n",
      "0.91\n",
      "0.9600000000000001\n",
      "0.01\n",
      "0.060000000000000005\n",
      "0.11\n",
      "0.16000000000000003\n",
      "0.21000000000000002\n",
      "0.26\n",
      "0.31000000000000005\n",
      "0.36000000000000004\n",
      "0.41000000000000003\n",
      "0.46\n",
      "0.51\n",
      "0.56\n",
      "0.6100000000000001\n",
      "0.66\n",
      "0.7100000000000001\n",
      "0.76\n",
      "0.81\n",
      "0.8600000000000001\n",
      "0.91\n",
      "0.9600000000000001\n",
      "0.01\n",
      "0.060000000000000005\n",
      "0.11\n",
      "0.16000000000000003\n",
      "0.21000000000000002\n",
      "0.26\n",
      "0.31000000000000005\n",
      "0.36000000000000004\n",
      "0.41000000000000003\n",
      "0.46\n",
      "0.51\n",
      "0.56\n",
      "0.6100000000000001\n",
      "0.66\n",
      "0.7100000000000001\n",
      "0.76\n",
      "0.81\n",
      "0.8600000000000001\n",
      "0.91\n",
      "0.9600000000000001\n",
      "0.01\n",
      "0.060000000000000005\n",
      "0.11\n",
      "0.16000000000000003\n",
      "0.21000000000000002\n",
      "0.26\n",
      "0.31000000000000005\n",
      "0.36000000000000004\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-129-12ed8a77929b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mswapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpick_swapvars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mdframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mswap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswapped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"swap_runs3/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mcounty\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"/similar/swap_\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"_a\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".csv\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mcsv_orig_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-127-1d02746e9378>\u001b[0m in \u001b[0;36mswap\u001b[1;34m(dfr, swaprate, swap, df_state)\u001b[0m\n\u001b[0;32m     68\u001b[0m                     \u001b[0mnew_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrace\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m                 \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrace\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m125\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m                     \u001b[0mnew_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrace\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m                 \u001b[0mi\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mappend\u001b[1;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[0;32m   7083\u001b[0m             \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7084\u001b[0m             \u001b[0mverify_integrity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7085\u001b[1;33m             \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7086\u001b[0m         )\n\u001b[0;32m   7087\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[0;32m    283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m             new_data = concatenate_block_managers(\n\u001b[1;32m--> 497\u001b[1;33m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    498\u001b[0m             )\n\u001b[0;32m    499\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m   2020\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2021\u001b[0m             b = make_block(\n\u001b[1;32m-> 2022\u001b[1;33m                 \u001b[0mconcatenate_join_units\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin_units\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2023\u001b[0m                 \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2024\u001b[0m             )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\concat.py\u001b[0m in \u001b[0;36mconcatenate_join_units\u001b[1;34m(join_units, concat_axis, copy)\u001b[0m\n\u001b[0;32m    246\u001b[0m     to_concat = [\n\u001b[0;32m    247\u001b[0m         \u001b[0mju\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_reindexed_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mempty_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mempty_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupcasted_na\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupcasted_na\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mju\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mjoin_units\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m     ]\n\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\concat.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    246\u001b[0m     to_concat = [\n\u001b[0;32m    247\u001b[0m         \u001b[0mju\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_reindexed_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mempty_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mempty_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupcasted_na\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupcasted_na\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mju\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mjoin_units\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m     ]\n\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\concat.py\u001b[0m in \u001b[0;36mget_reindexed_values\u001b[1;34m(self, empty_dtype, upcasted_na)\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malgos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake_nd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "states = ['california']\n",
    "counties = ['alameda']\n",
    "\n",
    "swaprates = np.arange(.01, 1.0, .05, float)\n",
    "k=0\n",
    "\n",
    "for i in range(0,len(states)):\n",
    "    county = counties[i]\n",
    "    state = states[i]\n",
    "    print(county, state)\n",
    "    df = import_countydata(county)\n",
    "    df_state = import_statedata(state)\n",
    "    while k <1:\n",
    "        for s in swaprates:\n",
    "            print(s)\n",
    "            s = float(s)\n",
    "            swapped = pick_swapvars(df)\n",
    "            dframe = swap(df, s, swapped, df_state)        \n",
    "            filename = \"swap_runs/\"+county+\"/similar/swap_\"+str(s)+\"_a\"+str(k)+\".csv\"\n",
    "            csv_orig_data = dframe.to_csv(filename, index = True)\n",
    "        k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [\"california\", \"pennsylvania\", \"newmexico\", \"georgia\", \"northdakota\", \"hawaii\", \"missouri\", \"massachussets\", \"vermont\"]\n",
    "\n",
    "counties = ['alameda', 'armstrong', 'cibola', 'fayette', 'grandforks', 'hawaii', 'jefferson', 'nantucket', 'washington']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alameda california\n",
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "0.01\n",
      "0.060000000000000005\n",
      "0.11\n",
      "0.16000000000000003\n",
      "0.21000000000000002\n",
      "0.26\n",
      "0.31000000000000005\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-126-7a445efac187>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mswapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpick_swapvars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0mdframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mswap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswapped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"swap_runs/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mcounty\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"/similar/swap_\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"_a\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".csv\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mcsv_orig_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-121-1b4b53eaf0b1>\u001b[0m in \u001b[0;36mswap\u001b[1;34m(dfr, swaprate, swap, df_state)\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m<=\u001b[0m\u001b[0mthreshold_race\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrace\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m                     \u001b[0mnew_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrace\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m                     \u001b[1;31m#new_data.append(df_state[race-i])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m                 \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrace\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m62\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mappend\u001b[1;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[0;32m   7083\u001b[0m             \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7084\u001b[0m             \u001b[0mverify_integrity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7085\u001b[1;33m             \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7086\u001b[0m         )\n\u001b[0;32m   7087\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[0;32m    283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m             new_data = concatenate_block_managers(\n\u001b[1;32m--> 497\u001b[1;33m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    498\u001b[0m             )\n\u001b[0;32m    499\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m   2020\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2021\u001b[0m             b = make_block(\n\u001b[1;32m-> 2022\u001b[1;33m                 \u001b[0mconcatenate_join_units\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin_units\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2023\u001b[0m                 \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2024\u001b[0m             )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\concat.py\u001b[0m in \u001b[0;36mconcatenate_join_units\u001b[1;34m(join_units, concat_axis, copy)\u001b[0m\n\u001b[0;32m    261\u001b[0m                 \u001b[0mconcat_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcat_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m         \u001b[0mconcat_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcat_compat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconcat_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mconcat_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\concat.py\u001b[0m in \u001b[0;36mconcat_compat\u001b[1;34m(to_concat, axis)\u001b[0m\n\u001b[0;32m    135\u001b[0m                 \u001b[0mto_concat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"object\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mto_concat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "swaprates = np.arange(.01, 1.0, .05, float)\n",
    "k=0\n",
    "\n",
    "for i in range(0,len(states)):\n",
    "    county = counties[i]\n",
    "    state = states[i]\n",
    "    print(county, state)\n",
    "    df = import_countydata(county)\n",
    "    df_state = import_statedata(state)\n",
    "    while k <50:\n",
    "        for s in swaprates:\n",
    "            print(s)\n",
    "            s = float(s)\n",
    "            swapped = pick_swapvars(df)\n",
    "            dframe = swap(df, s, swapped, df_state)        \n",
    "            filename = \"swap_runs/\"+county+\"/similar/swap_\"+str(s)+\"_a\"+str(k)+\".csv\"\n",
    "            csv_orig_data = dframe.to_csv(filename, index = True)\n",
    "    k+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
